<!-- http://www.w3.org/TR/mmi-discovery/ -->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
    "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html dir="ltr" xmlns="http://www.w3.org/1999/xhtml" lang="en"
xml:lang="en">
<head>
<meta name="generator" content="HTML Tidy, see www.w3.org" />
<title>Registration &amp; Discovery of Multimodal Modality
Components in Multimodal Systems: Use Cases and
Requirements</title>
<meta http-equiv="Content-Type"
content="text/html; charset=utf-8" />
<style type="text/css">
        /****************************************************************************
         * 2012 Modified by : B.Helena RODRIGUEZ ( berthele at soixante-dix punto com)
         * 2009 Created by : Robin Berjon (robin at berjon dot com)
         * v0.06
         * 
         *  Copyright 1997-2003 W3C (MIT, ERCIM, Keio). All Rights Reserved.
         * The following software licensing rules apply:
         * http://www.w3.org/Consortium/Legal/copyright-software 
         ****************************************************************************/

        body {
          padding: 2em 1em 2em 70px;
          margin: 0;
          font-family: sans-serif;
          color: black;
          background: white;
          background-position: top left;
          background-attachment: fixed;
          background-repeat: no-repeat;
          background-image: url(http://www.w3.org/StyleSheets/TR/logo-WG-Note);
        }
        :link { color: #00C; background: transparent }
        :visited { color: #609; background: transparent }
        a:active { color: #C00; background: transparent }

        a img { color: white; }        /* trick to hide the border in Netscape 4 */
        @media all {                   /* hide the next rule from Netscape 4 */
          a img { color: inherit; }    /* undo the color change above */
        }

        th, td { /* ns 4 */
          font-family: sans-serif;
        }

        h1, h2, h3, h4, h5, h6 { text-align: left }

        h1, h2, h3, h4 { color: #005A9C; background: white }
        h1 { font: 170% sans-serif }
        h2 { font: 140% sans-serif }
        h3 { font: 120% sans-serif }
        h4 { font: 110% sans-serif }
        h5 { font: italic 100% sans-serif }
        h6 { font: small-caps 100% sans-serif }

        .ReqsTable { border-left:  1px solid #CFE1FF; border-right:  1px solid #CFE1FF;width:80%; border-bottom:  1px solid #CFE1FF;
            margin-left:5%; }
        .headReqsTable { font: bold 103% sans-serif; border-top:  1px solid #CFE1FF; border-bottom:  1px solid #CFE1FF; background: #EEE; width:12%; }
        .subheadReqsTable { font: 100% sans-serif; border-top:  1px solid #CFE1FF; border-bottom:  1px solid #CFE1FF; background: #EEE; text-align:center;width:44%; }
        .sublineReqsTable { border-bottom:  1px solid #DDD; padding-top:5px;padding-bottom:5px; }


        .hide { display: none }

        div.head { margin-bottom: 1em }
        div.head h1 { margin-top: 2em; clear: both }
        div.head table { margin-left: 2em; margin-top: 2em }

        p.copyright { font-size: small }
        p.copyright small { font-size: small }

        @media screen {  /* hide from IE3 */
        a[href]:hover { background: #FFBBB2 }
        }

        pre { margin-left: 2em }

        dt, dd { margin-top: 0; margin-bottom: 0 } /* opera 3.50 */
        dt { font-weight: bold }

        pre, code { font-family: monospace } /* navigator 4 requires this */

        ul.toc, ol.toc {
          list-style: disc;     /* Mac NS has problem with 'none' */
          list-style: none;
        }

        @media aural {  
          h1, h2, h3 { stress: 20; richness: 90 }
          .hide { speak: none }
          p.copyright { volume: x-soft; speech-rate: x-fast }
          dt { pause-before: 20% }
          pre { speak-punctuation: code } 
        }


        /* --- INLINES --- */
 
        
        em.MMINote { 
            font-style:         italic;
            color:              #0F3E00;
        }
        

        h1 acronym, h2 acronym, h3 acronym, h4 acronym, h5 acronym, h6 acronym, a acronym,
        h1 abbr, h2 abbr, h3 abbr, h4 abbr, h5 abbr, h6 abbr, a abbr {
            border: none;
        }

        dfn {
            font-weight:    bold;
        }

        a.internalDFN {
            color:  inherit;
            border-bottom:  1px solid #CFE1FF;
            text-decoration:    none;
        }

        a.externalDFN {
            color:  inherit;
            border-bottom:  1px dotted #ccc;
            text-decoration:    none;
        }

        a.bibref {
            text-decoration:    none;
        }

        code {
            color:  #ff4500;
        }


        /* --- WEB IDL --- */
        pre.idl {
            border-top: 1px solid #90b8de;
            border-bottom: 1px solid #90b8de;
            padding:    1em;
            line-height:    120%;
        }

        pre.idl::before {
            content:    "WebIDL";
            display:    block;
            width:      150px;
            background: #90b8de;
            color:  #fff;
            font-family:    initial;
            padding:    3px;
            font-weight:    bold;
            margin: -1em 0 1em -1em;
        }

        .idlType {
            color:  #ff4500;
            font-weight:    bold;
            text-decoration:    none;
        }

        
/*        .mmImage { border: solid 1px black; width:403px height:268px;} */




        /*.idlModule*/
        /*.idlModuleID*/
        /*.idlInterface*/
        .idlInterfaceID, .idlDictionaryID {
            font-weight:    bold;
            color:  #005a9c;
        }

        .idlSuperclass {
            font-style: italic;
            color:  #005a9c;
        }

        /*.idlAttribute*/
        .idlAttrType, .idlFieldType, .idlMemberType {
            color:  #005a9c;
        }
        .idlAttrName, .idlFieldName, .idlMemberName {
            color:  #ff4500;
        }
        .idlAttrName a, .idlFieldName a, .idlMemberName a {
            color:  #ff4500;
            border-bottom:  1px dotted #ff4500;
            text-decoration: none;
        }

        /*.idlMethod*/
        .idlMethType {
            color:  #005a9c;
        }
        .idlMethName {
            color:  #ff4500;
        }
        .idlMethName a {
            color:  #ff4500;
            border-bottom:  1px dotted #ff4500;
            text-decoration: none;
        }

        /*.idlParam*/
        .idlParamType {
            color:  #005a9c;
        }
        .idlParamName {
            font-style: italic;
        }

        .extAttr {
            color:  #666;
        }

        /*.idlConst*/
        .idlConstType {
            color:  #005a9c;
        }
        .idlConstName {
            color:  #ff4500;
        }
        .idlConstName a {
            color:  #ff4500;
            border-bottom:  1px dotted #ff4500;
            text-decoration: none;
        }

        /*.idlException*/
        .idlExceptionID {
            font-weight:    bold;
            color:  #c00;
        }

        .idlTypedefID, .idlTypedefType {
            color:  #005a9c;
        }

        .idlRaises, .idlRaises a.idlType, .idlRaises a.idlType code, .excName a, .excName a code {
            color:  #c00;
            font-weight:    normal;
        }

        .excName a {
            font-family:    monospace;
        }

        .idlRaises a.idlType, .excName a.idlType {
            border-bottom:  1px dotted #c00;
        }

        .excGetSetTrue, .excGetSetFalse, .prmNullTrue, .prmNullFalse, .prmOptTrue, .prmOptFalse {
            width:  45px;
            text-align: center;
        }
        .excGetSetTrue, .prmNullTrue, .prmOptTrue { color:  #0c0; }
        .excGetSetFalse, .prmNullFalse, .prmOptFalse { color:  #c00; }

        .idlImplements a {
            font-weight:    bold;
        }

        dl.attributes, dl.methods, dl.constants, dl.fields, dl.dictionary-members {
            margin-left:    2em;
        }

        .attributes dt, .methods dt, .constants dt, .fields dt, .dictionary-members dt {
            font-weight:    normal;
        }

        .attributes dt code, .methods dt code, .constants dt code, .fields dt code, .dictionary-members dt code {
            font-weight:    bold;
            color:  #000;
            font-family:    monospace;
        }

        .attributes dt code, .fields dt code, .dictionary-members dt code {
            background:  #ffffd2;
        }

        .attributes dt .idlAttrType code, .fields dt .idlFieldType code, .dictionary-members dt .idlMemberType code {
            color:  #005a9c;
            background:  transparent;
            font-family:    inherit;
            font-weight:    normal;
            font-style: italic;
        }

        .methods dt code {
            background:  #d9e6f8;
        }

        .constants dt code {
            background:  #ddffd2;
        }

        .attributes dd, .methods dd, .constants dd, .fields dd, .dictionary-members dd {
            margin-bottom:  1em;
        }

        table.parameters, table.exceptions {
            border-spacing: 0;
            border-collapse:    collapse;
            margin: 0.5em 0;
            width:  100%;
        }
        table.parameters { border-bottom:  1px solid #90b8de; }
        table.exceptions { border-bottom:  1px solid #deb890; }

        .parameters th, .exceptions th {
            color:  #fff;
            padding:    3px 5px;
            text-align: left;
            font-family:    initial;
            font-weight:    normal;
            text-shadow:    #666 1px 1px 0;
        }
        .parameters th { background: #90b8de; }
        .exceptions th { background: #deb890; }

        .parameters td, .exceptions td {
            padding:    3px 10px;
            border-top: 1px solid #ddd;
            vertical-align: top;
        }

        .parameters tr:first-child td, .exceptions tr:first-child td {
            border-top: none;
        }

        .parameters td.prmName, .exceptions td.excName, .exceptions td.excCodeName {
            width:  100px;
        }

        .parameters td.prmType {
            width:  120px;
        }

        table.exceptions table {
            border-spacing: 0;
            border-collapse:    collapse;
            width:  100%;
        }

        /* --- TOC --- */
        .toc a {
            text-decoration:    none;
        }

        a .secno {
            color:  #000;
        }

        /* --- TABLE --- */
        table.simple {
            border-spacing: 0;
            border-collapse:    collapse;
            border-bottom:  3px solid #005a9c;
        }

        .simple th {
            background: #005a9c;
            color:  #fff;
            padding:    3px 5px;
            text-align: left;
        }

        .simple th[scope="row"] {
            background: inherit;
            color:  inherit;
            border-top: 1px solid #ddd;
        }

        .simple td {
            padding:    3px 10px;
            border-top: 1px solid #ddd;
        }

        .simple tr:nth-child(even) {
            background: #f0f6ff;
        }

        /* --- DL --- */
        .section dd > p:first-child {
            margin-top: 0;
        }

        .section dd > p:last-child {
            margin-bottom: 0;
        }

        .section dd {
            margin-bottom:  1em;
        }

        .section dl.attrs dd, .section dl.eldef dd {
            margin-bottom:  0;
        }

        /* --- EXAMPLES --- */
        pre.example {
            border-top: 1px solid #ff4500;
            border-bottom: 1px solid #ff4500;
            padding:    1em;
            margin-top: 1em;
        }

        pre.example::before {
            content:    "Example";
            display:    block;
            width:      150px;
            background: #ff4500;
            color:  #fff;
            font-family:    initial;
            padding:    3px;
            font-weight:    bold;
            margin: -1em 0 1em -1em;
        }

        /* --- EDITORIAL NOTES --- */
        .issue {
            padding:    1em;
            margin: 1em 0em 0em;
            border: 1px solid #f00;
            background: #ffc;
        }

        .issue::before {
            content:    "Issue";
            display:    block;
            width:  150px;
            margin: -1.5em 0 0.5em 0;
            font-weight:    bold;
            border: 1px solid #f00;
            background: #fff;
            padding:    3px 1em;
        }

        .note {
            margin: 1em 0em 0em;
            padding:    1em;
            border: 2px solid #cff6d9;
            background: #e2fff0;
        }

        .note::before {
            content:    "Note";
            display:    block;
            width:  150px;
            margin: -1.5em 0 0.5em 0;
            font-weight:    bold;
            border: 1px solid #cff6d9;
            background: #fff;
            padding:    3px 1em;
        }

        /* --- Best Practices --- */
        div.practice {
            border: solid #bebebe 1px;
            margin: 2em 1em 1em 2em;
        }

        span.practicelab {
            margin: 1.5em 0.5em 1em 1em;
            font-weight: bold;
            font-style: italic;
        }

        span.practicelab   { background: #dfffff; }

        span.practicelab {
            position: relative;
            padding: 0 0.5em;
            top: -1.5em;
        }

        p.practicedesc {
            margin: 1.5em 0.5em 1em 1em;
        }

        @media screen {
            p.practicedesc {
                position: relative;
                top: -2em;
                padding: 0;
                margin: 1.5em 0.5em -1em 1em;
            }
        }

        /* --- SYNTAX HIGHLIGHTING --- */
        pre.sh_sourceCode {
          background-color: white;
          color: black;
          font-style: normal;
          font-weight: normal;
        }

        pre.sh_sourceCode .sh_keyword { color: #005a9c; font-weight: bold; }           /* language keywords */
        pre.sh_sourceCode .sh_type { color: #666; }                            /* basic types */
        pre.sh_sourceCode .sh_usertype { color: teal; }                             /* user defined types */
        pre.sh_sourceCode .sh_string { color: red; font-family: monospace; }        /* strings and chars */
        pre.sh_sourceCode .sh_regexp { color: orange; font-family: monospace; }     /* regular expressions */
        pre.sh_sourceCode .sh_specialchar { color:  #ffc0cb; font-family: monospace; }  /* e.g., \n, \t, \\ */
        pre.sh_sourceCode .sh_comment { color: #A52A2A; font-style: italic; }         /* comments */
        pre.sh_sourceCode .sh_number { color: purple; }                             /* literal numbers */
        pre.sh_sourceCode .sh_preproc { color: #00008B; font-weight: bold; }       /* e.g., #include, import */
        pre.sh_sourceCode .sh_symbol { color: blue; }                            /* e.g., *, + */
        pre.sh_sourceCode .sh_function { color: black; font-weight: bold; }         /* function calls and declarations */
        pre.sh_sourceCode .sh_cbracket { color: red; }                              /* block brackets (e.g., {, }) */
        pre.sh_sourceCode .sh_todo { font-weight: bold; background-color: #00FFFF; }   /* TODO and FIXME */

        /* Predefined variables and functions (for instance glsl) */
        pre.sh_sourceCode .sh_predef_var { color: #00008B; }
        pre.sh_sourceCode .sh_predef_func { color: #00008B; font-weight: bold; }

        /* for OOP */
        pre.sh_sourceCode .sh_classname { color: teal; }

        /* line numbers (not yet implemented) */
        pre.sh_sourceCode .sh_linenum { display: none; }

        /* Internet related */
        pre.sh_sourceCode .sh_url { color: blue; text-decoration: underline; font-family: monospace; }

        /* for ChangeLog and Log files */
        pre.sh_sourceCode .sh_date { color: blue; font-weight: bold; }
        pre.sh_sourceCode .sh_time, pre.sh_sourceCode .sh_file { color: #00008B; font-weight: bold; }
        pre.sh_sourceCode .sh_ip, pre.sh_sourceCode .sh_name { color: #006400; }

        /* for Prolog, Perl... */
        pre.sh_sourceCode .sh_variable { color: #006400; }

        /* for LaTeX */
        pre.sh_sourceCode .sh_italics { color: #006400; font-style: italic; }
        pre.sh_sourceCode .sh_bold { color: #006400; font-weight: bold; }
        pre.sh_sourceCode .sh_underline { color: #006400; text-decoration: underline; }
        pre.sh_sourceCode .sh_fixed { color: green; font-family: monospace; }
        pre.sh_sourceCode .sh_argument { color: #006400; }
        pre.sh_sourceCode .sh_optionalargument { color: purple; }
        pre.sh_sourceCode .sh_math { color: orange; }
        pre.sh_sourceCode .sh_bibtex { color: blue; }

        /* for diffs */
        pre.sh_sourceCode .sh_oldfile { color: orange; }
        pre.sh_sourceCode .sh_newfile { color: #006400; }
        pre.sh_sourceCode .sh_difflines { color: blue; }

        /* for css */
        pre.sh_sourceCode .sh_selector { color: purple; }
        pre.sh_sourceCode .sh_property { color: blue; }
        pre.sh_sourceCode .sh_value { color: #006400; font-style: italic; }

        /* other */
        pre.sh_sourceCode .sh_section { color: black; font-weight: bold; }
        pre.sh_sourceCode .sh_paren { color: red; }
        pre.sh_sourceCode .sh_attribute { color: #006400; }

/* Kaz Ashimura - 4 July 2012 - for figures and captions */
img.mmImage {
  display: block;
  margin-left: auto;
  margin-right: auto;
  border: solid 1px black;
  width: 800px;
}
p.caption {
  text-align: center
}
        
</style>
<link href="http://www.w3.org/StyleSheets/TR/W3C-WG-NOTE" rel="stylesheet" type="text/css" charset="utf-8" />
</head>
<body style="display: inherit;">
<div class="head">
<p><a href="http://www.w3.org/"><img width="72" height="48"
src="http://www.w3.org/Icons/w3c_home" alt="W3C" /></a></p>

<h1 class="title" id="title">Registration &amp; Discovery of
Multimodal Modality Components in Multimodal Systems: Use Cases
and Requirements</h1>

<h2 id="w3c-MMI-working-group-note-12-june-2012"><acronym
title="World Wide Web Consortium">W3C</acronym> Working Group
Note 5 July 2012</h2>

<dl>
<dt>This version:</dt>

<dd><a
href="http://www.w3.org/TR/2012/NOTE-mmi-discovery-20120705/">http://www.w3.org/TR/2012/NOTE-mmi-discovery-20120705/</a></dd>

<dt>Latest published version:</dt>

<dd><a
href="http://www.w3.org/TR/mmi-discovery/">http://www.w3.org/TR/mmi-discovery/</a></dd>

<dt>Previous version:</dt>

<dd>none</dd>

<dt>Editor:</dt>

<dd><span>B. Helena Rodriguez</span>, <a
href="http://www.mines-telecom.fr">Institut Telecom</a></dd>

<dt>Authors:</dt>

<dd><span>Piotr Wiechno</span>, <a
href="http://www.orange.com/fr_FR/">France Telecom</a></dd>

<dd><span>Deborah Dahl</span>, <a
href="http://www.conversational-technologies.com/">W3C Invited
Experts</a></dd>

<dd><span>Kazuyuki Ashimura</span>, <a
href="http://www.w3.org/">W3C</a></dd>

<dd><span>Raj Tumuluri</span>, <a
href="http://www.openstream.com/">Openstream, Inc.</a></dd>
</dl>

<p class="copyright"><a href="http://www.w3.org/Consortium/Legal/ipr-notice#Copyright">Copyright</a> © 2012 <a href="http://www.w3.org/"><acronym title="World Wide Web Consortium">W3C</acronym></a><sup>®</sup> (<a href="http://www.csail.mit.edu/"><acronym title="Massachusetts Institute of Technology">MIT</acronym></a>, <a href="http://www.ercim.eu/"><acronym title="European Research Consortium for Informatics and Mathematics">ERCIM</acronym></a>, <a href="http://www.keio.ac.jp/">Keio</a>), All Rights Reserved. W3C <a href="http://www.w3.org/Consortium/Legal/ipr-notice#Legal_Disclaimer">liability</a>, <a href="http://www.w3.org/Consortium/Legal/ipr-notice#W3C_Trademarks">trademark</a> and <a href="http://www.w3.org/Consortium/Legal/copyright-documents">document use</a> rules apply.</p>

<hr />
</div>

<h2 id="abstract">Abstract</h2>

<p>This document addresses people who want either to develop
Modality Components for <a href="#dfn-application"
class="internalDFN">Applications</a> that communicate with the user
through different modalities such as voice, gesture, or
handwriting, and/or to distribute them through a multimodal system
using multi-biometric elements, multimodal interfaces or multi-sensor
recognizers over a local network or "in the cloud". With this goal,
this document collects a number of use cases together with their
goals and requirements for describing, publishing, discovering,
registering and subscribing to Modality Components in a system
implemented according the <a
href="http://www.w3.org/TR/2012/CR-mmi-arch-20120112/">Multimodal
Architecture Specification</a>. In this way, Modality Components can
be used by automated tools to power advanced <a href="#dfn-service"
class="internalDFN">Services</a> such as : more accurate searches
based on modality, behavior recognition for a better interaction
with intelligent software agents and an enhanced knowledge
management achieved by the means of capturing and producing
emotional data.</p>

<h2 id="sotd">Status of This Document</h2>

<p><em>This section describes the status of this document at the
time of its publication. Other documents may supersede this
document. A list of current <acronym
title="World Wide Web Consortium">W3C</acronym> publications and
the latest revision of this technical report can be found in the <a
href="http://www.w3.org/TR/"><acronym
title="World Wide Web Consortium">W3C</acronym> technical reports
index</a> at http://www.w3.org/TR/.</em></p>

<p>This is the 5 July 2012
<a href="http://www.w3.org/2005/10/Process-20051014/tr.html#WGNote"><acronym title="World
Wide Web Consortium">W3C</acronym> Working Group Note</a> of
&quot;Registration &amp; Discovery of Multimodal Modality Components
in Multimodal Systems: Use Cases and Requirements&quot;.

This <acronym title="World Wide Web Consortium">W3C</acronym> Working
Group Note has been developed by
the <a href="http://www.w3.org/2002/mmi/">Multimodal Interaction
Working Group</a> of the <acronym title="World Wide Web
Consortium">W3C</acronym> <a href="http://www.w3.org/2002/mmi/Activity.html">Multimodal
Interaction Activity</a>.</p>

<p>This document was published by
the <a href="http://www.w3.org/2002/mmi/">Multimodal Interaction
Working Group</a> as a Working Group Note. If you wish to make
comments regarding this document, please send them
to <a href="mailto:www-multimodal@w3.org">www-multimodal@w3.org</a>
(<a href="mailto:www-multimodal-request@w3.org?subject=subscribe">subscribe</a>, <a href="http://lists.w3.org/Archives/Public/www-multimodal/">archives</a>). All
comments are welcomed and should have a subject starting with the
prefix '[dis]'.</p>

<p>Publication as a Working Group Note does not imply endorsement by
the <acronym title="World Wide Web Consortium">W3C</acronym>
Membership. This is a draft document and may be updated, replaced or
obsoleted by other documents at any time. It is inappropriate to cite
this document as other than work in progress.</p>

<p>This document was produced by a group operating under
the <a href="http://www.w3.org/Consortium/Patent-Policy-20040205/">5
February 2004 <acronym title="World Wide Web Consortium">W3C</acronym>
Patent Policy</a>. <acronym title="World Wide Web
Consortium">W3C</acronym> maintains a <a rel="disclosure"
href="http://www.w3.org/2004/01/pp-impl/34607/status">public list of
any patent disclosures</a> made in connection with the deliverables of
the group; that page also includes instructions for disclosing a
patent. An individual who has actual knowledge of a patent which the
individual believes
contains <a href="http://www.w3.org/Consortium/Patent-Policy-20040205/#def-essential">Essential
Claim(s)</a> must disclose the information in accordance
with <a href="http://www.w3.org/Consortium/Patent-Policy-20040205/#sec-Disclosure">section
6 of the <acronym title="World Wide Web Consortium">W3C</acronym>
Patent Policy</a>.</p>

<h2 id="toc" class="introductory">Table of Contents</h2>

<ul class="toc">
<li class="tocline"><a href="#introduction" class="tocxref"><span
class="secno">1.</span> Introduction</a></li>

<li class="tocline"><a href="#vocabulary" class="tocxref"><span
class="secno">2.</span> Domain Vocabulary</a></li>

<li class="tocline"><a href="#use-cases" class="tocxref"><span
class="secno">3.</span> Use Cases</a></li>

<li class="tocline"><a href="#uc-set-1" class="tocxref"><span
class="secno">3.1.</span> Use Cases SET 1 : Smart Homes</a></li>

<li class="tocline"><a href="#uc-set-2" class="tocxref"><span
class="secno">3.2.</span> Use Cases SET 2 : Personal Externalized
Interfaces</a></li>

<li class="tocline"><a href="#uc-set-3" class="tocxref"><span
class="secno">3.3.</span> Use Cases SET 3 : Public Spaces</a></li>

<li class="tocline"><a href="#uc-set-4" class="tocxref"><span
class="secno">3.4.</span> Use Cases SET 4 : Health Sensing</a></li>

<li class="tocline"><a href="#uc-set-5" class="tocxref"><span
class="secno">3.5.</span> Use Cases SET 5 : Synergistic Interaction
and Recognition</a></li>

<li class="tocline"><a href="#requirements" class="tocxref"><span
class="secno">4.</span> Requirements</a></li>

<li class="tocline"><a href="#distribution"
class="tocxref"><span class="secno">4.1</span>
Distribution</a></li>

<li class="tocline"><a href="#advertisement"
class="tocxref"><span class="secno">4.2</span>
Advertisement</a></li>

<li class="tocline"><a href="#discovery"
class="tocxref"><span class="secno">4.3</span> Discovery</a></li>

<li class="tocline"><a href="#registration"
class="tocxref"><span class="secno">4.4</span>
Registration</a></li>

<li class="tocline"><a href="#query"
class="tocxref"><span class="secno">4.5</span> Querying</a></li>

<li class="tocline"><a href="#open-issues"
class="tocxref"><span class="secno">4.6</span> Open Issues</a></li>

<li class="tocline"><a href="#related-works" class="tocxref"><span
class="secno">5.</span> Related Work (Informative)</a></li>

<li class="tocline"><a href="#references" class="tocxref"><span
class="secno">A.</span> References</a></li>
</ul>

<h2 id="introduction"><span class="secno">1.</span> Introduction</h2>

<p>User interaction with Internet <a href="#dfn-application"
class="internalDFN">Applications</a> on mobile phones, personal
computers, tablets or other electronic <a href="#dfn-device"
class="internalDFN">Devices</a> is moving towards a multi-mode
environment in which important parts of the interaction are
supported in multiple ways. This heterogeneity is driven by <a
href="#dfn-application" class="internalDFN">Applications</a> that
compete to enrich the user experience in accessing all kinds of
services. More and more, <a href="#dfn-application"
class="internalDFN">Applications</a> need interaction variety,
which has been proven to provide numerous concurrent advantages. At
the same time, it brings new challenges in multimodal integration,
which is often quite difficult to handle in a context with multiple
networks and input/output resources.</p>

<p>Today, users, vendors, operators and broadcasters can produce
and use all kinds of different <a href="#dfn-media"
class="internalDFN">Media</a> and <a href="#dfn-device"
class="internalDFN">Devices</a> that are capable of supporting
multiple modes of input or output. In this context, tools for
authoring, edition or distribution of <a href="#dfn-media"
class="internalDFN">Media</a> for <a href="#dfn-application"
class="internalDFN">Application</a> developers are well documented.
Mature proprietary / open source tools and <a href="#dfn-service"
class="internalDFN">Services</a> that handle, capture, present,
play, annotate or recognize <a href="#dfn-media"
class="internalDFN">Media</a> in multiple modes are available.
Nevertheless, there is a lack of powerful tools or practices for a
richer integration and semantic synchronization of all these
media.</p>

<p>To the best of our knowledge, there is no standardized way to
build a web <a href="#dfn-application"
class="internalDFN">Application</a> that can dynamically combine
and control discovered modalities by querying a registry based on
user-experience data and modality states. This document describes
design requirements that the Multimodal Architecture and Interfaces
specification needs to cover in order to address this problem.</p>

<br />
<br />

<h2 id="vocabulary"><span class="secno">2.</span> Domain Vocabulary</h2>

<dl>
<dt><dfn id="dfn-context">Interaction Context</dfn></dt>

<dd>For the purposes of this document an Interaction Context
represents a single exchange between a system and one or multiple
users across one or multiple interaction modes and covers the
longest period of communication over which it would make sense for
components to keep the information available. It can be as simple
as a single period of audio visual content (e.g. a program ), a
phone call or a web session. But it can be also a richer
interaction combining for example, voice , gesture and a direct
interaction with a light pointer or a shared whiteboard with an
associated VoIP call that during the interaction evolves to a text
chat. In these cases, a single context persists across various
modality configurations. For more details see the multimodal <a
href="http://www.w3.org/TR/mmi-arch/#ComponentInterface">context</a>
in the MMI architecture.</dd>

<dt><dfn id="dfn-multimodal-system">Multimodal System</dfn></dt>

<dd>For the purposes of this document a <a
href="#dfn-multimodal-system" class="internalDFN">Multimodal System</a>
is any system communicating with the user through different
modalities such as voice, gesture, or handwriting in the same
interaction cycle identified by an unique <a href="#dfn-context"
class="internalDFN">context</a>. In a <a
href="#dfn-multimodal-system" class="internalDFN">Multimodal
System</a> the <a href="#dfn-application"
class="internalDFN">Application</a> or the final user can
dynamically switch <a href="#dfn-modality-component"
class="internalDFN">modalities</a> in the same <a
href="#dfn-context" class="internalDFN">context</a> of information
exchange. This is a bi-directional system with combined inputs and
outputs in multiple sensorial modes (e.g. visual, acoustic, haptic,
olfactive, gustative) and modalities (e.g. voice, gesture,
handwriting, biometrics capture, temperature sensing, etc). This is
also a system in which input and output data can be integrated [
See <a href="#dfn-fusion" class="internalDFN">Fusion</a> ] or
dissociated [ See <a href="#dfn-fission"
class="internalDFN">Fission</a> ] in order to identify the meaning
of the user's behavior or in order to compose a
more adapted, relevant and pertinent returning message using
multiple <a href="#dfn-media" class="internalDFN">media</a>, modes
and <a href="#dfn-modality-component"
class="internalDFN">modalities</a>. [ See a <a
href="#dfn-multimodal-system" class="internalDFN">Multimodal
System</a> <a
href="images/MMI-Modalites.png">
Example</a> ]<br />
<br />
 A <a href="#dfn-multimodal-system" class="internalDFN">Multimodal
System</a> can be any Infrastructure ( or any <acronym
title="Infrastructure as a Service">IaaS</acronym> ), any Platform
( or any <acronym title="Platform as a Service">PaaS</acronym> ) or
any Software ( on any <acronym
title="Software as a Service">SaaS</acronym> ) implementing
human-centered multimodal communication. For more information : [
See the basic component's <a
href="http://www.w3.org/TR/mmi-framework/#s2">Description</a> for a
Multimodal Interaction Framework ]</dd>

<dt><dfn id="dfn-modality-component">Modality Component</dfn></dt>

<dd>For the purpose of this document, a modality is a term that
covers the way an idea could be communicated or the manner an
action could be performed. In some mobile multimodal systems, e.g.
the primary modality is speech and an additional modality can be
typically gesture, gaze, sketch, or any combination thereof. These
are forms of representing information in a known and recognizable
logical structure. For example, acoustic data can be expressed as a
musical sound modality (e.g. a human singing) or as a speech
modality (e.g. a human talking). Following this idea, in this
document a <strong><a
href="http://www.w3.org/TR/mmi-arch/#ModalityComponents">Modality
Component</a></strong> is a logic entity that handles the input and
output of different hardware <a href="#dfn-device"
class="internalDFN">Devices</a> (e.g. microphone, graphic tablet,
keyboard) or software <a href="#dfn-service"
class="internalDFN">Services</a> (e.g. motion detection, biometric
changes) associated with the <a href="#dfn-multimodal-system"
class="internalDFN">Multimodal System</a>. Modality Components are
responsible for specific tasks, including handling inputs and
outputs in various ways, such as speech, writing, video, etc..
Modality Components are also loosely coupled software modules that
may be either co-resident on a <a href="#dfn-device"
class="internalDFN">device</a> or distributed across a
network.<br />
<br />
 For example, a <strong><a href="#dfn-modality-component"
class="internalDFN">Modality Component</a></strong> can be charged
at the same time of the speech recognition and the sound input
management (i.e. some advanced signal treatment task like source
separation). Another <a href="#dfn-modality-component"
class="internalDFN">Modality Component</a> can manage the
complementary command inputs on two different devices: a graphics
tablet and a microphone. Two modality components, can manage
separately two complementary inputs given by a single device: a
camcorder. Or finally, a <a href="#dfn-modality-component"
class="internalDFN">Modality Component</a>, can use an external
recognition web service and only be responsible for the control of
communication exchanges needed for the recognition task. [ See :
this <strong><a href="#dfn-modality-component"
class="internalDFN">Modality Component</a></strong> <a
href="images/MMI-MC.png">
Example</a> ]<br />
<br />
 In all four cases the system has a generic <strong><a
href="#dfn-modality-component" class="internalDFN">Modality
Component</a></strong> for the detection of a voice command input,
despite the differences of implementation. Any <strong><a
href="#dfn-modality-component" class="internalDFN">Modality
Component</a></strong> can potentially wrap multiple features
provided by multiple physical <a href="#dfn-device"
class="internalDFN">Devices</a> but also more than one <strong><a
href="#dfn-modality-component" class="internalDFN">Modality
Component</a></strong> could be included in a single device. To
this extent the <strong><a href="#dfn-modality-component"
class="internalDFN">Modality Component</a></strong> is an
abstraction of the same kind of input handled and implemented
differently in each case. For more information : [ See the
Multimodal Interaction Framework input/output <a
href="http://www.w3.org/TR/mmi-framework/#s3">Description</a>
]</dd>

<dt><dfn id="dfn-interaction-manager">Interaction
Manager</dfn></dt>

<dd>For the purposes of this document, the <a
href="http://www.w3.org/TR/mmi-arch/#d3e395">Interaction
Manager</a> is also a logical component handling the multimodal <a
href="#dfn-fusion" class="internalDFN">integration</a> and <a
href="#dfn-fission" class="internalDFN">composition</a>. It is
responsible for all message exchanges between the components of the
<a href="#dfn-multimodal-system" class="internalDFN">Multimodal
System</a> and the hosting runtime framework [ See : <a
href="images/MMI-Arch.png">
Architecture Components</a> ]. This is a communication bus and also
an event handler. Each <a href="#dfn-application"
class="internalDFN">Application</a> can configure at least one
Interaction Manager to define the required interaction logic. This
is a controller at the core of all the multimodal interaction : 

<ul>
<li>It manages the specific behaviors triggered by the <a
href="http://www.w3.org/TR/mmi-arch/#LifeCycleEvents">events</a>
exchanged between the various input and output components.</li>

<li>It manages the communication between the modules and the client
application.</li>

<li>It ensures consistency between multiple inputs and outputs and
provides a general perception of the application's current
status.</li>

<li>It is responsible for data <a href="#dfn-fission"
class="internalDFN">synchronization</a>.</li>

<li>It is responsible for focus management.</li>

<li>It manages communication with any other entity outside the
system.</li>
</ul>

For more information : [ See the Multimodal Interaction Framework
<a href="http://www.w3.org/TR/mmi-framework/#s6">Description</a> of
an <a href="#dfn-interaction-manager"
class="internalDFN">Interaction Manager</a> ]</dd>

<dt><dfn id="dfn-data-component">Data Component</dfn></dt>

<dd>For the purposes of this document a <strong><a
href="http://www.w3.org/TR/mmi-arch/#d3e423">Data
Component</a></strong> is a logic entity that stores the public and
private data of any module in a <a href="#dfn-multimodal-system"
class="internalDFN">Multimodal System</a>. The data component's
primary role is to save the public data that may be required by one
or several <strong><a href="#dfn-modality-component"
class="internalDFN">Modality Components</a></strong> or by other
modules (eg, a session component in the hosting framework ). The
<strong>Data Component</strong> can be an internal module or an
external module [ See : <a
href="images/MMI-DC_cases.png">
Example</a> ]. This depends on the implementation chosen by each <a
href="#dfn-application" class="internalDFN">application</a>.
However, the <strong><a href="#dfn-interaction-manager"
class="internalDFN">Interaction Manager</a></strong> is the only
module that has direct access to the <strong>Data
Component</strong> and only <strong><a
href="#dfn-interaction-manager" class="internalDFN">Interaction
Manager</a></strong> can view and edit the data and communicate
with external servers if necessary. As a result, the <strong><a
href="#dfn-modality-component" class="internalDFN">Modality
Components</a></strong> must use an <strong><a
href="#dfn-interaction-manager" class="internalDFN">Interaction
Manager</a></strong> as a mediator to access any private or public
data in the case of an implementation following the <a
href="images/MMI-RusianDoll.png">
principle of nested dolls</a> given by the MMI Architecture
Specification [ See : <a
href="http://www.w3.org/TR/mmi-arch/#Runtime">MMI Recursion</a> ].
For the storage of private data, each <strong><a
href="#dfn-modality-component" class="internalDFN">Modality
Component</a></strong> can implement its own <strong>Data
Component</strong>. This private <strong>Data Component</strong>
accesses external servers and keeps the data that the <strong><a
href="#dfn-modality-component" class="internalDFN">Modality
Components</a></strong> may require, for example, in the speech
recognition task. For more information : [ See the Multimodal
Interaction Framework <a
href="http://www.w3.org/TR/mmi-framework/#s7">Description</a> of an
Session Component ]</dd>

<dt><dfn id="dfn-application">Application</dfn></dt>

<dd>For the purposes of this document, the term <a
href="#dfn-application" class="internalDFN">Application</a> refers
to a collection of events, components and resources which use
server-side or client-side processing and the <a
href="http://www.w3.org/TR/mmi-arch/">Multimodal Architecture
Specification</a> to provide sensorial, cognitive and emotional
information [ See : <a
href="http://www.w3.org/2005/Incubator/emotion/XGR-emotion/#AppendixUseCases">
Emotion Use Cases</a> ] through a rich multimodal user experience.
For example, a multimodal <a href="#dfn-application"
class="internalDFN">Application</a> can be implemented to use in an
integrated way, mobile <a href="#dfn-device"
class="internalDFN">Devices</a> and cell phones, home appliances,
Internet of Things objects, television and home networks,
enterprise applications, web applications, "smart" cars or medical
devices.</dd>

<dt><dfn id="dfn-service">Service</dfn></dt>

<dd>For the purposes of this document, a <a href="#dfn-service"
class="internalDFN">Service</a> is a set of functionalities
associated with a process or system that performs a task and is
wrapped in a <a href="#dfn-modality-component"
class="internalDFN">Modality Component</a> abstraction. While most
of the industrial approaches for s ervice discovery use hardware <a
href="#dfn-device" class="internalDFN">Devices</a> as networked <a
href="#dfn-service" class="internalDFN">Services</a> and the
majority of web services discovery approaches consider a <a
href="#dfn-service" class="internalDFN">Service</a> as a software
component performing a specific functionality, our definition
covers both views and focuses on the Multimodal Component
abstraction. Thus, a multimodal <a href="#dfn-service"
class="internalDFN">Service</a> is any functionality wrapped in a
Multimodal Component (e.g. a <strong><a
href="#dfn-modality-component" class="internalDFN">Modality
Component</a></strong> or the <strong><a
href="#dfn-interaction-manager" class="internalDFN">Interaction
Manager</a></strong>) and using one or multiple devices, device's
services, <a href="#dfn-device" class="internalDFN">Devices</a>
APIs or web services. For example, in the case of a <strong><a
href="#dfn-modality-component" class="internalDFN">Modality
Component</a></strong> a <a href="#dfn-service"
class="internalDFN">Service</a> is a functionality provided to
handle input or output interaction in one or more devices, sensors,
effectors, players (e.g. for virtual reality <a href="#dfn-media"
class="internalDFN">Media</a> display), on-demand <a
href="http://en.wikipedia.org/wiki/Software_as_a_service"><acronym
title="Software as a Service">SaaS</acronym></a> Recognizers (e.g.
for natural language recognition) and on-demand <acronym
title="Software as a Service">SaaS</acronym> User Interface Widgets
(e.g. for geolocation display).<br />
<br />
 For the purposes of this document, we will use the term <a
href="#dfn-service" class="internalDFN">Service</a> Description as
a set of attributes (metadata) describing a particular service. The
term Service Advertisement refers to the publication of the
metadata and the <a href="#dfn-service"
class="internalDFN">Service</a> itself by indexing the <a
href="#dfn-service" class="internalDFN">Service</a> in some
registry and making available the <a href="#dfn-service"
class="internalDFN">Service</a> to the client's requests.</dd>

<dt><dfn id="dfn-device">Device</dfn></dt>

<dd>For the purposes of this document, a <a href="#dfn-device"
class="internalDFN">Device</a> is any hardware material resource
wrapped in a <strong><a href="#dfn-modality-component"
class="internalDFN">Modality Component</a></strong>. The MMI
Architecture does not describe how <strong><a
href="#dfn-modality-component" class="internalDFN">Modality
Components</a></strong> are allocated to hardware devices, this is
dependent on the implementation. A <a href="#dfn-device"
class="internalDFN">Device</a> can act as an input sensor. In this
case, for example, cameras, haptic devices, microphones, biometric
devices, keyboards, mouse and writing tablets; are devices that
provide input <a href="#dfn-service"
class="internalDFN">Services</a> wrapped in one or many <strong><a
href="#dfn-modality-component" class="internalDFN">Modality
Components</a></strong>. A <a href="#dfn-device"
class="internalDFN">Device</a> can also act as an output effector.
In this case displays, speakers, pressure applicators, projectors,
<a href="#dfn-media" class="internalDFN">Media</a> players,
vibrating <a href="#dfn-device" class="internalDFN">Devices</a> and
even some sensor <a href="#dfn-device"
class="internalDFN">Devices</a> (galvanic skins, switches, motion
platforms) can provide effector <a href="#dfn-service"
class="internalDFN">Services</a> wrapped in one or many <strong><a
href="#dfn-modality-component" class="internalDFN">Modality
Components</a></strong> implemented in the <a
href="#dfn-multimodal-system" class="internalDFN">Multimodal
System</a>.</dd>

<dt><dfn id="dfn-media">Media</dfn></dt>

<dd>For the purposes of this document, the multimodal <a
href="#dfn-media" class="internalDFN">Media</a> are resources
depending on the semantics of the message, the user/author goals
and the capabilities of the support itself. The multimodal <a
href="#dfn-media" class="internalDFN">Media</a> adhere to a certain
content mode (e.g. visual) and <a href="#dfn-modality-component"
class="internalDFN">modality</a> (e.g. animated image) and can be a
document, a stream, a set of data or any other conventional logical
entity to represent the information that is communicated through <a
href="#dfn-device" class="internalDFN">devices</a>, <a
href="#dfn-service" class="internalDFN">services</a> and networks.
In a <a href="#dfn-multimodal-system"
class="internalDFN">Multimodal System</a>, <a href="#dfn-media"
class="internalDFN">Media</a> can be played, displayed, recognized,
touched, scented, heard, shaken, pushed, shared, adapted, fused,
composed, etc.. and annotated to enhance integration, recognition,
composition and interpretation [ See the use cases for MultiModal
<a href="#dfn-media" class="internalDFN">Media</a> Annotation with
<a href="http://www.w3.org/TR/emma-usecases/">EMMA</a> ].</dd>

<dt><dfn id="dfn-fusion">Fusion</dfn></dt>

<dd>For the purposes of this document, the multimodal <a
href="#dfn-fusion" class="internalDFN">Fusion</a> mechanism is the
integration of data from multiple <strong><a
href="#dfn-modality-component" class="internalDFN">Modality
Components</a></strong> to produce specific and comprehensive
unified information about the interaction. The goal of the
multimodal <a href="#dfn-fusion" class="internalDFN">Fusion</a> is
to integrate the data coming from a set of input <strong><a
href="#dfn-modality-component" class="internalDFN">Modality
Components</a></strong> or to integrate data in the actions to be
executed by a set of output <strong><a
href="#dfn-modality-component" class="internalDFN">Modality
Components</a></strong>.</dd>

<dt><dfn id="dfn-fission">Fission</dfn></dt>

<dd>For the purposes of this document, the multimodal <a
href="#dfn-fission" class="internalDFN">Fission</a> mechanism
refers to the <a href="#dfn-media" class="internalDFN">media</a>
composition phenomenon: this is the process of realizing a single
message on some combination of the available <a
href="#dfn-modality-component" class="internalDFN">modalities</a>
for more than one sensorial mode. This process occurs before the
processes that are dedicated to the information rendering or to the
<a href="#dfn-media" class="internalDFN">Media</a> restitution. The
goal is to generate an adequate message, according to the space (in
the car, home, conference room), current activity (course,
conference, brainstorm) or preferences and profile (chair of the
conference, blind user, elderly). A <a href="#dfn-fission"
class="internalDFN">Fission</a> component determines which are the
most relevant <a href="#dfn-modality-component"
class="internalDFN">modalities</a>, selects which <a
href="#dfn-media" class="internalDFN">media</a> has the best
content to return with the <strong><a
href="#dfn-modality-component" class="internalDFN">Modality
Components</a></strong> available in the given conditions; and
coordinates this final result [ See the MMI Architecture <a
href="http://www.w3.org/TR/mmi-arch/#LifeCycleEvents">Standard
Life-Cycle Events</a> ]. In this way, the multimodal <a
href="#dfn-fission" class="internalDFN">Fission</a> mechanism
handles the repartition of information among several <strong><a
href="#dfn-modality-component" class="internalDFN">Modality
Components</a></strong> and resolves which part of the content will
be generated within each <strong><a href="#dfn-modality-component"
class="internalDFN">Modality Component</a></strong> when the global
multimodal content has been defined.</dd>
</dl>

<p>&nbsp;</p>

<h2 id="use-cases"><span class="secno">3.</span> Use Cases</h2>

This section is a non-exhaustive list of use cases that would be
enabled by implementing the Discovery &amp; Register of Modality
Components. Each use case is written according a template that is
inspired on the <a
href="http://www.w3.org/TR/2011/NOTE-hnreq-20111201/#use-cases">Requirements
for Home Networking Scenarios</a> Use Cases template. This allows
to locate our proposal in relation with the cases covered by the
Web and TV Interest Group. Each use case is structured as a list
of:<br />
<br />
<strong>[Code]</strong><br />
In the form UC X.X (ucSet.ucNumber)<br />
 <strong>[Description]</strong><br />
 A High level description of the use case<br />
 <strong>[Motivation]</strong><br />
 Explanation of the need that addresses the use case.<br />
 <strong>[Requirements]</strong><br />
 List of requirements implied by this Use Case in two columns: a
low level requirement and a high level requirement; both related to
the MMI Architecture specification.<br />
 

<h3 id="uc-set-1"><span class="secno">3.1</span> Use Cases SET 1 : Smart
Homes</h3>

Multimodality as an assistive support in intimate, personal and
social spaces. Home appliances, entertainment equipment and
intelligent home <a href="#dfn-device"
class="internalDFN">Devices</a> are available as modality
components for applications. These appliances can also provide
their own <a href="#dfn-interaction-manager"
class="internalDFN">Interaction Managers</a> that connect to the
multimodal interface on a smartphone to enable control of
intelligent home features through the user's mobile device.

<h4 id="audio-visual-devices"><span class="secno">3.1.1</span> Audiovisual Devices Acting as Smartphone Extensions</h4>

A home entertainment system providing user interface components to
command and extend a mobile application.<br />
<br />
 

<table class='ReqsTable'>
<tr>
<td class='headReqsTable' colspan="3">Code</td>
</tr>

<tr>
<td colspan="3">[ UC 1.1 ]</td>
</tr>

<tr>
<td class='headReqsTable' colspan="3">Description</td>
</tr>

<tr>
<td colspan="3">A home entertainment system is adapted by a mobile
<a href="#dfn-device" class="internalDFN">Device</a> as a set of
user interface components.<br />
<br />
 In addition to <a href="#dfn-media" class="internalDFN">Media</a>
rendering and playback, these <a href="#dfn-device"
class="internalDFN">Devices</a> also act as input modalities for
the smartphone's applications. The mobile <a href="#dfn-device"
class="internalDFN">Device</a> does not have to be manipulated
directly at all. A wall-mounted touch-sensitive TV can be used to
navigate applications, and a wide-range microphone can handle
speech input. Spatial (Kinect-style) gestures may also be used to
control <a href="#dfn-application"
class="internalDFN">Application</a> behavior.<br />
<br />
 The smartphone discovers available modalities and arranges them to
best serve the user's purpose. One display can be used to show
photos and movies, another for navigation. As the user walks into
another room, this configuration is adapted dynamically to the new
location. User intervention may be sometimes required to decide on
the most convenient modality configuration. The state of the
interaction is maintained while switching between modality sets.
For example, if the user was navigating a GUI menu in the living
room, it is carried over to another screen when she switches rooms,
or replaced with a different modality such as voice if there are no
displays in the new location.</td>
</tr>

<tr>
<td class='headReqsTable' colspan="3">Motivation</td>
</tr>

<tr>
<td colspan="3">Many of today's home <a href="#dfn-device"
class="internalDFN">Devices</a> can provide similar functionality
(e.g. audio/video playback), differing only in certain aspects of
the user interface. This allows continuous interaction with a
specific <a href="#dfn-application"
class="internalDFN">Application</a> as the user moves from room to
room, with the user interface switched automatically to the set of
<a href="#dfn-device" class="internalDFN">Devices</a> available in
the user's present location.<br />
<br />
 On the other hand, some <a href="#dfn-device"
class="internalDFN">Devices</a> can have specific capabilities and
user interfaces that can be used to add information to a larger
context that can be reused by other <a href="#dfn-application"
class="internalDFN">Applications</a> and devices. This drives the
need to spread an <a href="#dfn-application"
class="internalDFN">Application</a> across different <a
href="#dfn-device" class="internalDFN">Devices</a> to achieve a
more user-adapted and meaningful interaction according to the
context of use. Both aspects provide arguments for exploring use
cases where <a href="#dfn-application"
class="internalDFN">Applications</a> use distributed multimodal
interfaces.<br />
<br />
 </td>
</tr>

<tr>
<td class='headReqsTable'>Requirements</td>
<td class='subheadReqsTable'>Low-Level</td>
<td class='subheadReqsTable'>High-Level</td>
</tr>

<tr>
<td class='sublineReqsTable'>Distribution</td>
<td class='sublineReqsTable'>Lan</td>
<td class='sublineReqsTable'>Any</td>
</tr>

<tr>
<td class='sublineReqsTable'>Advertisement</td>
<td class='sublineReqsTable'>Devices Description</td>
<td class='sublineReqsTable'>Modality Component's Description</td>
</tr>

<tr>
<td class='sublineReqsTable'>Discovery</td>
<td class='sublineReqsTable'>The <a href="#dfn-application"
class="internalDFN">Application</a> must handle MMI
requests/responses</td>
<td class='sublineReqsTable'>Fixed, Mediated, Active or
Passive</td>
</tr>

<tr>
<td class='sublineReqsTable'>Registration</td>
<td class='sublineReqsTable'>The <a href="#dfn-application"
class="internalDFN">Application</a> must use the Status Event to
provide the Modality Component's Description and the register
lifetime information.</td>
<td class='sublineReqsTable'>Hard-State</td>
</tr>

<tr>
<td>Querying</td>
<td>The <a href="#dfn-application"
class="internalDFN">Application</a> must send MMI
requests/responses</td>
<td>Queries searching for attributes in the Description of the
Modality Component (a predefined MC Data Model needed)</td>
</tr>
</table>

<h4 id="intelligent-home-apparatus"><span class="secno">3.1.2</span> Intelligent Home
Apparatus</h4>

Mobile <a href="#dfn-device" class="internalDFN">Devices</a> as
command mediators to control intelligent home apparatus.<br />
<br />
 

<table class='ReqsTable'>
<tr>
<td class='headReqsTable' colspan="3">Code</td>
</tr>

<tr>
<td colspan="3">[ UC 1.2 ]</td>
</tr>

<tr>
<td class='headReqsTable' colspan="3">Description</td>
</tr>

<tr>
<td colspan="3">Smart home functionality (window blinds/lights/air
conditioning etc.) is controlled through a multimodal interface,
composed from modalities built into the house itself (e.g. speech
and gesture recognition) and those available on the user's personal
<a href="#dfn-device" class="internalDFN">Devices</a> (e.g.
smartphone touchscreen). The system may automatically adapt to the
preferences of a specific user, or enter a more complex interaction
if multiple people are present.<br />
<br />
 Sensors built into various <a href="#dfn-device"
class="internalDFN">Devices</a> around the house can act as input
modalities that feed information to the home and affect its
behavior. For example, lights and temperature in the gym room can
be adapted dynamically as workout intensity recorded by the fitness
equipment increases. The same data can also increase or decrease
volume and tempo of music tracks played by the user's mobile <a
href="#dfn-device" class="internalDFN">Device</a> or the home's <a
href="#dfn-media" class="internalDFN">Media</a> system. In
addition, the intelligent home in tandem with the user's personal
<a href="#dfn-device" class="internalDFN">Devices</a> can monitor
user behavior for emotional patterns such as 'tired' or 'busy' and
adapt further.</td>
</tr>

<tr>
<td class='headReqsTable' colspan="3">Motivation</td>
</tr>

<tr>
<td colspan="3">The increase in the number of controllable <a
href="#dfn-device" class="internalDFN">Devices</a> in an
intelligent home creates a problem with controlling all available
services in a coherent and useful manner. Having a shared context
-built from information collected through sensors and direct user
input - would improve recognition of user intent, and thus simplify
interactions.<br />
<br />
 In addition, multiple input mechanisms could be selected by the
user based on <a href="#dfn-device" class="internalDFN">Device</a>
type, level of trust and the type of interaction required for a
particular task.</td>
</tr>

<tr>
<td class='headReqsTable'>Requirements</td>
<td class='subheadReqsTable'>Low-Level</td>
<td class='subheadReqsTable'>High-Level</td>
</tr>

<tr>
<td class='sublineReqsTable'>Distribution</td>
<td class='sublineReqsTable'>Lan, Wan</td>
<td class='sublineReqsTable'>Any</td>
</tr>

<tr>
<td class='sublineReqsTable'>Advertisement</td>
<td class='sublineReqsTable'>Application Manifests, <a
href="#dfn-device" class="internalDFN">Device</a> Description</td>
<td class='sublineReqsTable'>Modality Component's Description</td>
</tr>

<tr>
<td class='sublineReqsTable'>Discovery</td>
<td class='sublineReqsTable'>The <a href="#dfn-application"
class="internalDFN">Application</a> must handle MMI
requests/responses</td>
<td class='sublineReqsTable'>Fixed</td>
</tr>

<tr>
<td class='sublineReqsTable'>Registration</td>
<td class='sublineReqsTable'>The Modality Component's Description
and the register lifetime information may be predefined in the home
server.</td>
<td class='sublineReqsTable'>Hard-State</td>
</tr>

<tr>
<td>Querying</td>
<td>The <a href="#dfn-application"
class="internalDFN">Application</a> must send MMI
requests/responses</td>
<td>MMI Lifecycle Events using knowing descriptions</td>
</tr>
</table>

<br />
<br />

<h3 id="uc-set-2"><span class="secno">3.2</span> Use Cases SET 2 : Personal Externalized Interfaces</h3>

Multimodality as a way to simplify and personalize interaction
with complex <a href="#dfn-device" class="internalDFN">Devices</a>
that are shared by family or close friends, for example cars. The
user's personal mobile <a href="#dfn-device"
class="internalDFN">Device</a> communicates with the external
shared equipment in a way that enables the functionality of one to
be available through the interface of the other.

<h4 id="smart-cars"><span class="secno">3.2.1</span> Smart Cars</h4>

Multimodality as a nomadic tool to configure user interfaces
provided in Smart Cars.<br />
<br />
 

<table class='ReqsTable'>
<tr>
<td class='headReqsTable' colspan="3">Code</td>
</tr>

<tr>
<td colspan="3">[ UC 2.1 ]</td>
</tr>

<tr>
<td class='headReqsTable' colspan="3">Description</td>
</tr>

<tr>
<td colspan="3">Basic in-car functionality is standardized to be
managed by other devices. A user can control seat, radio or AC
settings through a personalized multimodal interface shared by the
car and her personal mobile device. User preferences are stored on
the mobile <a href="#dfn-device" class="internalDFN">Device</a> (or
in the cloud), and can be transferred across different car models
handling a specific functionality (e.g. all cars with touchscreens
should be able to adapt to a "high contrast" preference).<br />
<br />
 The car can make itself available as a complex modality component
that wraps around all functionality and supported modalities, or as
a collection of modality components such as touchscreen / speech
recognition / audio player. In the latter case, certain user
preferences may be shared with other environments.<br />
<br />
 For example, a user may opt to select the "high contrast" scheme
at night on all of her displays, in the car or at home. A car that
provides a set of modalities can be also adapted by the mobile <a
href="#dfn-device" class="internalDFN">Device</a> to compose an
interface for its functionality, for example manage playback of
music tracks through the car's voice control system. Sensor data
provided by the phone can be mixed with data recorded by the car's
own sensors to profile user behavior which can be used as context
in multimodal interaction.</td>
</tr>

<tr>
<td class='headReqsTable' colspan="3">Motivation</td>
</tr>

<tr>
<td colspan="3">User interface personalization is a task that most
often needs to be repeated for all <a href="#dfn-device"
class="internalDFN">Devices</a> a user wishes to interact with
recurringly. With complex devices, this task can also be very
time-consuming, which is problematic if the user regularly accesses
similar, but not identical <a href="#dfn-device"
class="internalDFN">Devices</a> -as in the case of several cars
rented over a month.<br />
<br />
 A standardized set of personal information and preferences that
could be used to configure personalizable <a href="#dfn-device"
class="internalDFN">Devices</a> automatically would be very helpful
for all these cases in which the interaction becomes a customary
practice.<br />
<br />
 </td>
</tr>

<tr>
<td class='headReqsTable'>Requirements</td>
<td class='subheadReqsTable'>Low-Level</td>
<td class='subheadReqsTable'>High-Level</td>
</tr>

<tr>
<td class='sublineReqsTable'>Distribution</td>
<td class='sublineReqsTable'>Lan, Wan, Man</td>
<td class='sublineReqsTable'>Distributed</td>
</tr>

<tr>
<td class='sublineReqsTable'>Advertisement</td>
<td class='sublineReqsTable'>Constructor-Dependent</td>
<td class='sublineReqsTable'>Modality Component's Description</td>
</tr>

<tr>
<td class='sublineReqsTable'>Discovery</td>
<td class='sublineReqsTable'>The <a href="#dfn-application"
class="internalDFN">Application</a> must handle MMI
requests/responses</td>
<td class='sublineReqsTable'>Fixed, Mediated</td>
</tr>

<tr>
<td class='sublineReqsTable'>Registration</td>
<td class='sublineReqsTable'>Multi-node Registry</td>
<td class='sublineReqsTable'>Soft-State</td>
</tr>

<tr>
<td>Querying</td>
<td>The <a href="#dfn-application"
class="internalDFN">Application</a> must send MMI
requests/responses</td>
<td>Requests limited to a federated group of MC</td>
</tr>
</table>

<br />
<br />

<h3 id="uc-set-3"><span class="secno">3.3</span> Use Cases SET 3 : Public Spaces</h3>

Multimodality as a way to access public <a href="#dfn-device"
class="internalDFN">Devices</a> to perform tasks or for fun.
Functionality of a user's personal <a href="#dfn-device"
class="internalDFN">Device</a> is projected to modality components
available in the immediate proximity. Public <a href="#dfn-device"
class="internalDFN">Devices</a> present a multimodal interface
tailored to the user's preferences. The user's mobile <a
href="#dfn-device" class="internalDFN">Device</a> can also
advertise itself as a modality component to allow for direct
targeted messaging without privacy abuse.

<h4 id="interactive-spaces"><span class="secno">3.3.1</span> Interactive Spaces</h4>

Multimodality as a support for advertising and accessing
information on public user interfaces.<br />
<br />
 

<table class='ReqsTable'>
<tr>
<td class='headReqsTable' colspan="3">Code</td>
</tr>

<tr>
<td colspan="3">[ UC 3.1 ]</td>
</tr>

<tr>
<td class='headReqsTable' colspan="3">Description</td>
</tr>

<tr>
<td colspan="3">Interactive installations such as touch-sensitive
or gesture-tracking billboards are set up in public places. Objects
that present public information (e.g. a map of a shopping mall) can
use a multimodal interface (built-in or in tandem with the user's
mobile devices) to simplify user interaction and provide faster
access. Other setups can stimulate social activities, allowing
multiple people to enter an interaction simultaneously to work
together towards a certain goal (for a prize) or just for fun (e.g.
play a musical instrument or control a lighting exhibition). In a
context where privacy is an issue (for example, with
targeted/personalized alerts or advertisements), the user's mobile
<a href="#dfn-device" class="internalDFN">Device</a> acts as a
complex modality component or a set of modality components for an
<a href="#dfn-interaction-manager" class="internalDFN">Interaction
Manager</a> running on the public network. This allows the user to
receive relevant information in the way she sees fit. These alerts
can serve as triggers for interaction with public <a
href="#dfn-device" class="internalDFN">Devices</a> if the user
chooses to do so.</td>
</tr>

<tr>
<td class='headReqsTable' colspan="3">Motivation</td>
</tr>

<tr>
<td colspan="3">Public spaces provide many opportunities for
engaging, social and fun interaction. At the same time, preserving
privacy while sharing tasks and activities with other people is a
major issue in ambient systems. These systems may also deliver
personalized information in tandem with more general services
presented publicly.<br />
<br />
 A trustful discovery of the Modality Components available in such
environments is a necessity to guarantee personalization and
privacy in public-space applications.</td>
</tr>

<tr>
<td class='headReqsTable'>Requirements</td>
<td class='subheadReqsTable'>Low-Level</td>
<td class='subheadReqsTable'>High-Level</td>
</tr>

<tr>
<td class='sublineReqsTable'>Distribution</td>
<td class='sublineReqsTable'>Lan, Wan, Man</td>
<td class='sublineReqsTable'>Any</td>
</tr>

<tr>
<td class='sublineReqsTable'>Advertisement</td>
<td class='sublineReqsTable'>Application Manifests, <a
href="#dfn-device" class="internalDFN">Device</a> Description, User
Profile</td>
<td class='sublineReqsTable'>Modality Component's Description</td>
</tr>

<tr>
<td class='sublineReqsTable'>Discovery</td>
<td class='sublineReqsTable'>The <a href="#dfn-application"
class="internalDFN">Application</a> must handle MMI
requests/responses</td>
<td class='sublineReqsTable'>Fixed, Mediated, Passive, Active</td>
</tr>

<tr>
<td class='sublineReqsTable'>Registration</td>
<td class='sublineReqsTable'>The Modality Component's Description
and the register lifetime information may be predefined in the
space server.</td>
<td class='sublineReqsTable'>Soft-State</td>
</tr>

<tr>
<td>Querying</td>
<td>The <a href="#dfn-application"
class="internalDFN">Application</a> must send MMI
requests/responses</td>
<td>Requests limited to a federated group of MC</td>
</tr>
</table>

<h4 id="in-office-events-assistance"><span class="secno">3.3.2</span> In-Office Events Assistance</h4>

Automatic in-office presentation hardware
projectors/speakers/ASR/gesture tracking controlled through a
mobile device<br />
<br />
 

<table class='ReqsTable'>
<tr>
<td class='headReqsTable' colspan="3">Code</td>
</tr>

<tr>
<td colspan="3">[ UC 3.2 ]</td>
</tr>

<tr>
<td class='headReqsTable' colspan="3">Description</td>
</tr>

<tr>
<td colspan="3">A conference room where a series of meetings will
take place. People can go in and out of the room before, after and
during the meeting. The door is "touched" by a badge. The system
activates any available display in the room and the room and the
event default <a href="#dfn-application"
class="internalDFN">Applications</a> : the outline modality
component, the notification <a href="#dfn-modality-component"
class="internalDFN">Modality Component</a> and the guiding <a
href="#dfn-modality-component" class="internalDFN">Modality
Component</a>. The chair of the meeting is notified by a
dynamically composed graphic animation, audio notification or a
mobile phone notification, about the <a
href="#dfn-modality-component" class="internalDFN">Modality
Components</a> availability with a shortcut to the default <a
href="#dfn-application" class="internalDFN">Application</a>
instance endpoint.<br />
<br />
 The chair of the meeting selects a setup procedure by text amongst
the discovered options. These options could be, for example: photo
step-by-step instructions (smartphone, HDTV display, Web site),
audio Instructions (Mp3 audio guide, Room speakers reproduction,
HDTV audio) or RFID enhanced instructions (mobile SmartTag Reader,
RFID Reader for smartphone). The chair of the meeting chooses the
room speakers reproduction, the guiding <a href="#dfn-service"
class="internalDFN">Service</a> is activated and he starts to set
the video projector. Then some attendees arrived. The chair of the
meeting changes to the slide show option and continues to follow
the instructions at the same step it was paused but with another
more private modality for example, a smartphone slideshow.</td>
</tr>

<tr>
<td class='headReqsTable' colspan="3">Motivation</td>
</tr>

<tr>
<td colspan="3">Meeting Room environments are more and more
complex. During meetings room setup users spend a lot of time
trying to put up presentations and make remote connections: a task
that usually affects his emotional state producing anxiety and
increasing his stress level. Assistance <a href="#dfn-application"
class="internalDFN">Applications</a> using modality discovery can
reduce the task load and the cognitive load for the user with
reassuring multimodal context-aware interfaces.</td>
</tr>

<tr>
<td class='headReqsTable'>Requirements</td>
<td class='subheadReqsTable'>Low-Level</td>
<td class='subheadReqsTable'>High-Level</td>
</tr>

<tr>
<td class='sublineReqsTable'>Distribution</td>
<td class='sublineReqsTable'>Lan, Wan</td>
<td class='sublineReqsTable'>Any</td>
</tr>

<tr>
<td class='sublineReqsTable'>Advertisement</td>
<td class='sublineReqsTable'>Application Manifests, <a
href="#dfn-device" class="internalDFN">Device</a> Description,
Situation Description, User Profile</td>
<td class='sublineReqsTable'>Modality Component's Description</td>
</tr>

<tr>
<td class='sublineReqsTable'>Discovery</td>
<td class='sublineReqsTable'>The <a href="#dfn-application"
class="internalDFN">Application</a> must handle MMI
requests/responses</td>
<td class='sublineReqsTable'>Fixed, Passive</td>
</tr>

<tr>
<td class='sublineReqsTable'>Registration</td>
<td class='sublineReqsTable'>One part of the <a
href="#dfn-modality-component" class="internalDFN">Modality
Component's</a> Description and the register lifetime information
may be predefined in the space server.</td>
<td class='sublineReqsTable'>Soft-State, Hard-State</td>
</tr>

<tr>
<td>Querying</td>
<td>The <a href="#dfn-application"
class="internalDFN">Application</a> must send MMI
requests/responses</td>
<td>Requests limited to a federated group of <a
href="#dfn-modality-component" class="internalDFN">Modality
Components</a></td>
</tr>
</table>

<br />
<br />

<h3 id="uc-set-4"><span class="secno">3.4</span> Use Cases SET 4 : Health Sensing</h3>

Multimodality as sensor and control support for medical reporting. 

<h4 id="health-notifiers"><span class="secno">3.4.1</span> Health Notifiers</h4>

Multimodal <a href="#dfn-application"
class="internalDFN">Applications</a> to alert and report medical
data.<br />
<br />
 

<table class='ReqsTable'>
<tr>
<td class='headReqsTable' colspan="3">Code</td>
</tr>

<tr>
<td colspan="3">[ UC 4.1 ]</td>
</tr>

<tr>
<td class='headReqsTable' colspan="3">Description</td>
</tr>

<tr>
<td colspan="3">In medical facilities, a complex <a
href="#dfn-modality-component" class="internalDFN">Modality
Component</a> provide multiple options to control sensor operations
by voice or gesture ("start reading my blood pressure now") for
example. The complex <a href="#dfn-modality-component"
class="internalDFN">Modality Component</a> is attached to a
smartphone. The <a href="#dfn-application"
class="internalDFN">Application</a> integrates information from
multiple sensors (for example, blood pressure and heart rate);
reports medical sensor readings periodically (for example, to a
remote medical facility) and sends alerts when unusual
readings/events are detected.</td>
</tr>

<tr>
<td class='headReqsTable' colspan="3">Motivation</td>
</tr>

<tr>
<td colspan="3">In critical situations regarding health, like
medical urgency, multimodality is the most effective way to
communicate alerts. With this goal a dynamic and effective <a
href="#dfn-modality-component" class="internalDFN">Modality
Component</a> discovery is needed. This is also the case when the
goal is to monitor the health evolution of a person in all its
complexity with rich media.</td>
</tr>

<tr>
<td class='headReqsTable'>Requirements</td>
<td class='subheadReqsTable'>Low-Level</td>
<td class='subheadReqsTable'>High-Level</td>
</tr>

<tr>
<td class='sublineReqsTable'>Distribution</td>
<td class='sublineReqsTable'>Lan</td>
<td class='sublineReqsTable'>Any</td>
</tr>

<tr>
<td class='sublineReqsTable'>Advertisement</td>
<td class='sublineReqsTable'>Application Manifests, <a
href="#dfn-device" class="internalDFN">Device</a> Description, User
Profile</td>
<td class='sublineReqsTable'>Modality Component's Description</td>
</tr>

<tr>
<td class='sublineReqsTable'>Discovery</td>
<td class='sublineReqsTable'>The <a href="#dfn-application"
class="internalDFN">Application</a> must handle MMI
requests/responses</td>
<td class='sublineReqsTable'>Fixed, Passive</td>
</tr>

<tr>
<td class='sublineReqsTable'>Registration</td>
<td class='sublineReqsTable'>The Modality Component's Description
and the register lifetime information may be predefined in the
space server.</td>
<td class='sublineReqsTable'>Hard-State</td>
</tr>

<tr>
<td>Querying</td>
<td>The <a href="#dfn-application"
class="internalDFN">Application</a> must send MMI
requests/responses</td>
<td>Queries to a Centralized Registry</td>
</tr>
</table>

<br />
<br />

<h3 id="uc-set-5"><span class="secno">3.5</span> Use Cases SET 5 : Synergistic Interaction and Recognition</h3>

Automatic discovery of <a href="#dfn-modality-component"
class="internalDFN">Modality Component's</a> resources providing
high-level features of recognition and analysis to adapt
application <a href="#dfn-service" class="internalDFN">Services</a>
and user interfaces, track the user behavior and assist the user in
temporary difficult tasks.

<h4 id="multimodal-support-to-recognition"><span class="secno">3.5.1</span> Multimodal support to recognition</h4>

<table class='ReqsTable'>
<tr>
<td class='headReqsTable' colspan="3">Code</td>
</tr>

<tr>
<td colspan="3">[ UC 5.1 ]</td>
</tr>

<tr>
<td class='headReqsTable' colspan="3">Description</td>
</tr>

<tr>
<td colspan="3">A modality component is an audio recognizer trained
with the more common sounds in the house to alert in case of
emergency. In the same house security <a href="#dfn-application"
class="internalDFN">Application</a> uses a video recognizer to
identify people at the front door. These two <a
href="#dfn-modality-component" class="internalDFN">Modality
Component's'</a> advertise some features, to cooperate with a
remote home management <a href="#dfn-application"
class="internalDFN">Application</a> using a discovery mechanism for
its <a href="#dfn-fission" class="internalDFN">Fission</a> feature.
The <a href="#dfn-application" class="internalDFN">Application</a>
validates and completes both recognition results while using
them.</td>
</tr>

<tr>
<td class='headReqsTable' colspan="3">Motivation</td>
</tr>

<tr>
<td colspan="3">The current recognizer system development has
arrived to a point of maturity where if we want to dramatically
enhance recognition, multimodal complementary results will be
needed. In order to achieve this, an image recognizer can use
results coming from other kind of recognizers (e.g. audio
recognizer) within the network engaged in the same interaction
cycle.</td>
</tr>

<tr>
<td class='headReqsTable'>Requirements</td>
<td class='subheadReqsTable'>Low-Level</td>
<td class='subheadReqsTable'>High-Level</td>
</tr>

<tr>
<td class='sublineReqsTable'>Distribution</td>
<td class='sublineReqsTable'>Lan, Wan, Man</td>
<td class='sublineReqsTable'>Any</td>
</tr>

<tr>
<td class='sublineReqsTable'>Advertisement</td>
<td class='sublineReqsTable'>Application Manifests</td>
<td class='sublineReqsTable'>Modality Component's Description</td>
</tr>

<tr>
<td class='sublineReqsTable'>Discovery</td>
<td class='sublineReqsTable'>The <a href="#dfn-application"
class="internalDFN">Application</a> must handle MMI
requests/responses</td>
<td class='sublineReqsTable'>Fixed, Passive</td>
</tr>

<tr>
<td class='sublineReqsTable'>Registration</td>
<td class='sublineReqsTable'>The Modality Component's Description
and the register lifetime information may be predefined in the
server.</td>
<td class='sublineReqsTable'>Hard-State</td>
</tr>

<tr>
<td>Querying</td>
<td>The <a href="#dfn-application"
class="internalDFN">Application</a> must send MMI
requests/responses</td>
<td>Queries to a Centralized Registry</td>
</tr>
</table>

<h4 id="discovery-to-enhance-synergic-interaction"><span class="secno">3.5.2</span> Discovery to enhance synergic interaction</h4>

Multimodal discovery as a tool to avoid difficult
interaction.<br />
<br />
 

<table class='ReqsTable'>
<tr>
<td class='headReqsTable' colspan="3">Code</td>
</tr>

<tr>
<td colspan="3">[ UC 5.2 ]</td>
</tr>

<tr>
<td class='headReqsTable' colspan="3">Description</td>
</tr>

<tr>
<td colspan="3">A person working mostly with a pc having a problem
with his right arm and hands. He is unable to use a mouse or a
keyboard for a few months. He can point at things, sketch, clap,
make gestures, but he can not make any precise movements. An <a
href="#dfn-application" class="internalDFN">Application</a>
proposes a generic interface to allow this person the access to his
most important tasks in his personal devices: to call someone, open
a mailbox, access his agenda or navigate over some Web pages. It
proposes child-oriented intuitive interfaces like a clapping-based
<a href="#dfn-modality-component" class="internalDFN">Modality
Component</a>, a very articulated TTS component or reduced gesture
input widgets. Other <a href="#dfn-modality-component"
class="internalDFN">Modality Components</a> like phone <a
href="#dfn-device" class="internalDFN">Devices</a> with very big
numbers, very simple remote controls, screens displaying text at
high resolution, voice command <a href="#dfn-device"
class="internalDFN">Devices</a> based on a reduced number or orders
can be used.</td>
</tr>

<tr>
<td class='headReqsTable' colspan="3">Motivation</td>
</tr>

<tr>
<td colspan="3">One of the main indicators concerning the usability
of an <a href="#dfn-application"
class="internalDFN">Application</a> is the corresponding level of
accessibility provided by it. The opportunity for all the users to
receive and to deliver all kinds of information, regardless of the
information format or the type of user profile, state or impairment
is a recurrent need in web applications. One of the means to
achieve accessibility is the design of a more synergic interaction
based on the discovery of multimodal <a
href="#dfn-modality-component" class="internalDFN">Modality
Components</a>.<br />
<br />
 Synergy is two or more entities functioning together to produce a
result that is not obtainable independently. It means "working
together". For example, in nomadic <a href="#dfn-application"
class="internalDFN">Applications</a> (always affected by the
changing context) to avoid disruptive interaction is an important
issue. In these applications, user interaction is difficult,
distracted and less precise. Multimodal discovery can increase
synergic interaction offering new possibilities more adapted to the
current disruptive. A well-founded discovery mechanism can enhance
the <a href="#dfn-fusion" class="internalDFN">Fusion</a> process
for target groups of users experiencing permanent or temporary
learning difficulties or with sensorial, emotional or social
impairments.</td>
</tr>

<tr>
<td class='headReqsTable'>Requirements</td>
<td class='subheadReqsTable'>Low-Level</td>
<td class='subheadReqsTable'>High-Level</td>
</tr>

<tr>
<td class='sublineReqsTable'>Distribution</td>
<td class='sublineReqsTable'>Lan, Wan, Man</td>
<td class='sublineReqsTable'>Any</td>
</tr>

<tr>
<td class='sublineReqsTable'>Advertisement</td>
<td class='sublineReqsTable'>Application Manifests, <a
href="#dfn-device" class="internalDFN">Device</a> Description, User
Profile</td>
<td class='sublineReqsTable'>Modality Component's Description</td>
</tr>

<tr>
<td class='sublineReqsTable'>Discovery</td>
<td class='sublineReqsTable'>The <a href="#dfn-application"
class="internalDFN">Application</a> must handle MMI
requests/responses</td>
<td class='sublineReqsTable'>Fixed, Mediated, Passive, Active</td>
</tr>

<tr>
<td class='sublineReqsTable'>Registration</td>
<td class='sublineReqsTable'>Multi-node Registry</td>
<td class='sublineReqsTable'>Soft-State</td>
</tr>

<tr>
<td>Querying</td>
<td>The <a href="#dfn-application"
class="internalDFN">Application</a> must send MMI
requests/responses</td>
<td>Distributed Registry. Handled by pattern matching</td>
</tr>
</table>

<p>&nbsp;</p>

<h2 id="requirements"><span class="secno">4.</span> Requirements</h2>

<h3 id="distribution"><span class="secno">4.1</span> Distribution</h3>

<a href="#dfn-modality-component" class="internalDFN">Modality
Components</a> can be distributed in a centralized way, an hybrid
way or a fully decentralized way. For the Discovery &amp; Register
purposes the distribution of the <a href="#dfn-modality-component"
class="internalDFN">Modality Components</a> influences how many
requests the <a href="#dfn-multimodal-system"
class="internalDFN">Multimodal System</a> can handle in a given
time interval, and how efficiently it can execute these requests.
The MMI Architecture Specification is distribution-agnostic. <a
href="#dfn-modality-component" class="internalDFN">Modality
Components</a> can be located anywhere: in a local network or in
the web. The decision about how to distribute the Multimodal
Constituents depends on the implementation.<br />

<h3 id="advertisement"><span class="secno">4.2</span> Advertisement</h3>

Advertisement of <a href="#dfn-modality-component"
class="internalDFN">Modality Components</a> is one of the most
influential criteria to evaluate how well the system can discover
<a href="#dfn-modality-component" class="internalDFN">Modality
Components</a>, starting from the description mechanism. This
allows the <a href="#dfn-multimodal-system"
class="internalDFN">Multimodal System</a> to reach correctness in
the <a href="#dfn-modality-component" class="internalDFN">Modality
Components</a> retrieval, because a pertinent and expressive
description enables the result to match more closely to the
application's or user's request. On the other hand, Advertisement
also affects the completeness in the <a
href="#dfn-modality-component" class="internalDFN">Modality
Component</a> retrieval. To return all matching instances
registered and corresponding to the user's request, the request
criteria must match to some basic attributes defined in the <a
href="#dfn-modality-component" class="internalDFN">Modality
Component's</a> Description. A <a href="#dfn-modality-component"
class="internalDFN">Modality Component's</a> Description that lists
some multimodal attributes and actions is required.<br />
<br />
 For this reason, conforming specifications <em class="MMINote"
title="should">should</em> provide a means for <a
href="#dfn-application" class="internalDFN">applications</a> to
advertise <a href="#dfn-modality-component"
class="internalDFN">Modality Components</a> in any of the
distributions enumerated in <a href="#distribution"
class="internalDFN">section 5.1.</a><br />
<br />
 This <a href="#dfn-modality-component"
class="internalDFN">Modality Component's'</a> Description can be
expressed as a data structure (e.g. <a
href="http://www.itu.int/ITU-T/asn1/introduction/index.htm"
target="_blank">ASN.1</a>) as a simple attribute-value pairs list,
as a list of attributes with hierarchical tree relationships (e.g.
the intentional name schema in <a
href="http://nms.csail.mit.edu/projects/ins/">INS</a>) , as a <a
href="http://www.w3.org/TR/wsdl20/">WSDL</a> document or as an <a
href="http://www.w3.org/TR/xml11/">XML</a> manifest document. The
language and form of the document is <a href="#dfn-application"
class="internalDFN">Application</a> dependent.<br />
<br />
 The kind of data described by this document depends also on the
implementation and some examples of the information that could be
advertised can be found in the <a
href="http://www.w3.org/TR/2011/NOTE-mmi-mcbp-20110301/">Best
practices for creating MMI Modality Components</a>.<br />
For instance, the <a href="#dfn-modality-component"
class="internalDFN">Modality Component's'</a> Description data can
describe :

<ul>
<li>Information about the of the identity <a
href="#dfn-modality-component" class="internalDFN">Modality
Component</a> :<br />
 For example the unique identifier of the <a
href="#dfn-modality-component" class="internalDFN">Modality
Component</a>, its name, address, port number, its embedded <a
href="#dfn-device" class="internalDFN">Device</a> or service,
constructor, version, transport protocol or lifetime.<br />
<br />
</li>

<li>Information about the of the behavior of the <a
href="#dfn-modality-component" class="internalDFN">Modality
Component</a> :<br />
 The list of content or <a href="#dfn-media"
class="internalDFN">Media</a> handled by the <a
href="#dfn-modality-component" class="internalDFN">Modality
Component</a>; a list of the commands or actions (e.g. described as
a service, functionality, operation or activity), to which the <a
href="#dfn-modality-component" class="internalDFN">Modality
Component</a> responds; parameters or arguments for each action;
and information variables that models the state of the <a
href="#dfn-modality-component" class="internalDFN">Modality
Component</a>.<br />
<br />
</li>

<li>Information about the of the context of use of the <a
href="#dfn-modality-component" class="internalDFN">Modality
Component</a> :<br />
 This may cover the name of the organization providing the <a
href="#dfn-modality-component" class="internalDFN">Modality
Component</a>, its authorizations, authentication procedures,
privacy policies, its business type (e.g. its <a
href="http://uddi.org/pubs/uddi_v3.htm">UDDI</a> businessService),
its access point , complementary information about invocation
policies or implementation details.<br />
<br />
</li>

<li>Information about the semantics of the <a
href="#dfn-modality-component" class="internalDFN">Modality
Component</a> for an specific domain :<br />
 A <a href="#dfn-modality-component" class="internalDFN">Modality
Component</a> type that can be application-specific or can follow
some specification (e.g. <a
href="http://www.upnp.org/specs/av/UPnP-av-ContentDirectory-v4-Service-20101231.pdf">
UPnP</a>, <a
href="http://www.echonet.gr.jp/english/spec/pdf/spec_v1e_appendix.pdf">
ECHONET</a> or <a href="http://www.iana.org/domains">IANA</a>)
depending on the implementation. The <a
href="#dfn-modality-component" class="internalDFN">Modality
Component's'</a> federation group (e.g. the Zone in AppleTalk Name
Binding Protocol or the DNS subdomain), its scope (e.g. like UA
scopes in <a href="http://www.ietf.org/rfc/rfc2608.txt">SLP</a>),
its category, its intent (e.g. like <a
href="http://developer.android.com/reference/android/content/Intent.html">
Implicit Intents</a> in Android or <a
href="http://webintents.org/">Web Intents</a>) or any other
semantic metadata.</li>
</ul>

<br />
A data model with some examples of attributes specific to the
multimodal domain can be suggested by the MMI Architecture
Specification to guarantee interoperability, expressiveness and
relevance in the description's content from a Multimodal
Interaction point of view. In this way, this data model can be used
also as information support for the annotation, for the modality
selection and for the <a href="#dfn-fusion"
class="internalDFN">Fusion</a> and <a href="#dfn-fission"
class="internalDFN">Fission</a> mechanisms in the analyzers or
synthesizers implemented in the <a href="#dfn-multimodal-system"
class="internalDFN">Multimodal System</a>.<br />
<br />
 As an example, Figure 1 shows a manifest that can be created at
Design Time or at Load Time, and that can be joined by a list of <a
href="#dfn-media" class="internalDFN">Media</a> handled by the <a
href="#dfn-modality-component" class="internalDFN">Modality
Component</a>. It can be an annotated list of <a href="#dfn-media"
class="internalDFN">Media</a> (e.g. <a
href="http://www.w3.org/TR/2009/REC-emma-20090210/">EMMA</a>) and
its URIs.<br />
<br />
<a href="images/Advertise.png">
<img class="mmImage" src="images/Advertise.png" alt="Manifest that can be created either at design time or at load time"/></a><br />
<p class="caption">Figure 1: Manifest that can be created either at Design Time or at Load Time</p>
<br />
 To store these descriptions, the MMI <a href="#dfn-data-component"
class="internalDFN">Data Component</a> <em class="MMINote"
title="must">must</em> be used as a directory support in a
centralized or a distributed manner.<br />
<br />
 A centralized registry hosted by a <a href="#dfn-data-component"
class="internalDFN">Data Component</a> <em class="MMINote"
title="should">should</em> provide a register of <a
href="#dfn-modality-component" class="internalDFN">Modality
Components</a> states and their descriptions; if the problems
associated with having a centralized registry such as a single
point of failure, bottlenecks, the scalability of data replication,
the notification to subscribers when performing system upgrades or
handling versioning of <a href="#dfn-service"
class="internalDFN">Services</a> are not an issue. This decision
will depend on the kind of <a href="#dfn-application"
class="internalDFN">Application</a> being implemented.<br />
<br />
 A distributed registry hosted by multiple <a
href="#dfn-data-component" class="internalDFN">Data Components</a>
<em class="MMINote" title="should">should</em> provide multiple
public or private registries . <a href="#dfn-data-component"
class="internalDFN">Data Components</a> can be federated in groups
following a mechanism similar to P2P or <a
href="http://lsdis.cs.uga.edu/projects/meteor-s/">METEOR-S</a>
registries, if conducting inquiries across the federated
environment of <a href="#dfn-data-component"
class="internalDFN">Data Components</a> in a time consuming manner
or the risk of some inconsistencies are not an issue. This decision
also will depend on the kind of <a href="#dfn-application"
class="internalDFN">Application</a> to implement.<br />
<br />
 Depending on the parameters given by the <a
href="#dfn-application" class="internalDFN">Application</a> logic,
the distribution of the <a href="#dfn-modality-component"
class="internalDFN">Modality Components</a> or the <a
href="#dfn-context" class="internalDFN">context of interaction</a>,
the advertisement can persist or not. It <em class="MMINote"
title="should">should</em> be a hard-state advertisement with an
infinite <a href="#dfn-modality-component"
class="internalDFN">Modality Component</a> lifetime or <em
class="MMINote" title="should">should</em> be a soft-state
advertisement, in which a life-time is associated to the <a
href="#dfn-modality-component" class="internalDFN">Modality
Component</a> (e.g. the timestamps assigned with <a
href="http://www.ogf.org/documents/GFD.80.pdf">OGSA</a>), and if it
is not renewed before expiration, the <a
href="#dfn-modality-component" class="internalDFN">Modality
Component</a> will be assumed as no longer available .<br />
<br />
 The communication model used by the registries in the <a
href="#dfn-data-component" class="internalDFN">Data Component</a>
<em class="MMINote" title="must">must</em> be specified by the
interaction life-cycle events of the MMI Architecture. The <a
href="#dfn-data-component" class="internalDFN">Data Component</a>
deliver the descriptions of the <a href="#dfn-modality-component"
class="internalDFN">Modality Components</a> by an exchange of
request and responses with MMI events.<br />
<br />

<h3 id="discovery"><span class="secno">4.3</span> Discovery</h3>

The MMI Architecture specification doesn't focus on the
discovery implementation and is not language-oriented.<br />
 There could be various approaches of implementations for the
discovery of <a href="#dfn-modality-component"
class="internalDFN">Modality Components</a>, e.g <a
href="http://www.ecma-international.org/publications/standards/Ecma-262.htm">
ECMAScript</a> or any other language. Any infrastructure can be
used as well.<br />
<br />
 Nevertheless, conforming specifications <em class="MMINote"
title="must">must</em> use the protocol proposed by the interaction
life-cycle events to discover <a href="#dfn-modality-component"
class="internalDFN">Modality Components</a>. Bootstrapping
properties can be specified in a generic way based on <a
href="#dfn-modality-component" class="internalDFN">Modality
Component</a> types defined by a domain taxonomy. These properties
play an important role on the announcement to the discovery
mechanism.<br />
<br />
 For example, at Load Time, on bootstrapping, when access to the
registry is not preconfigured, the <a
href="#dfn-interaction-manager" class="internalDFN">Interaction
Manager</a> can try to discover <a href="#dfn-modality-component"
class="internalDFN">Modality Components</a> using one of this four
mechanisms : fixed discovery, mediated discovery, active discovery
or passive discovery.<br />
<br />
 In the fixed discovery case, the <a
href="#dfn-interaction-manager" class="internalDFN">Interaction
Manager</a> and the <a href="#dfn-modality-component"
class="internalDFN">Modality Components</a> are assumed to know
their address and the port number to listen. In this way, the <a
href="#dfn-interaction-manager" class="internalDFN">Interaction
Manager</a> can send a request via the StatusRequest/StatusResponse pair
to the <a href="#dfn-modality-component"
class="internalDFN">Modality Component</a> asking for availability,
manifest address and <a href="#dfn-media"
class="internalDFN">Media</a> list, as showed in Figure 2. In other
implementations, the <a href="#dfn-modality-component"
class="internalDFN">Modality Component</a> can also announce its
availability and description directly to the <a
href="#dfn-interaction-manager" class="internalDFN">Interaction
Manager</a> using the same event.<br />
<br />
<a href="images/Discover.png">
<img class="mmImage" src="images/Discover.png" alt="Interaction Manager sending a request via the StatusRequest/StatusResponse pair to the Modality Components" /></a><br />
<p class="caption">Figure 2: Interaction Manager sending a request via the StatusRequest/StatusResponse pair to the Modality Components</p>
<br />
 In mediated discovery, the <a href="#dfn-interaction-manager"
class="internalDFN">Interaction Manager</a> can use the scanning
features provided by the underlying network (e.g. use DHCP) looking
for <a href="#dfn-modality-component" class="internalDFN">Modality
Components</a> tagged in their descriptions with a specific group
label (e.g. in federated distributions). If the Modality Component
is not tagged it can use some generic mechanism provided only to
subscribe to a generic 'welcome' group (e.g. in <a
href="http://jxta.kenai.com/Specifications/JXTAProtocols2_0.pdf">JXTA</a>
implementations). In this case, the <a
href="#dfn-modality-component" class="internalDFN">Modality
Component</a> <em class="MMINote" title="should">should</em> send a
request via the Status event to the <a
href="#dfn-interaction-manager" class="internalDFN">Interaction
Manager</a> subscribing to the register. After the bootstrapping
mechanism, the <a href="#dfn-interaction-manager"
class="internalDFN">Interaction Manager</a> can aks for a manifest
address and the <a href="#dfn-media" class="internalDFN">Media</a>
list address needed for advertisement. In other implementations the
<a href="#dfn-modality-component" class="internalDFN">Modality
Component</a> can send it directly to the register after
bootstrapping.<br />
<br />
 In active discovery, the <a href="#dfn-interaction-manager"
class="internalDFN">Interaction Manager</a> can initiate a
multicast, anycast or broadcast request or any other push mechanism
depending on the underlying networking mechanism implemented. This
<em class="MMINote" title="should">should</em> be done via the
Status Event or the Extension Notification defined by the MMI
Architecture.<br />
<br />
 And finally in passive discovery, the <a
href="#dfn-interaction-manager" class="internalDFN">Interaction
Manager</a> can listen to advertisement messages coming from <a
href="#dfn-modality-component" class="internalDFN">Modality
Components</a> over the network in a known port. In this case, the
<a href="#dfn-interaction-manager" class="internalDFN">Interaction
Manager</a> may provide some directory <a href="#dfn-service"
class="internalDFN">Service</a> feature (e.g. acting as a <a
href="http://river.apache.org/about.html">Jini</a> Lookup Service
or the <a
href="http://www.upnp.org/specs/arch/UPnP-arch-DeviceArchitecture-v1.0-20081015.pdf">
UPnP</a> control points), looking for the <a
href="#dfn-modality-component" class="internalDFN">Modality
Component's'</a> announcements that <em class="MMINote"
title="should">should</em> be published with the Status Event or
the Extension Notification. More precise details of the discovery
protocols are out of scope for this document and are implementation
dependent.

<h3 id="registration"><span class="secno">4.4</span> Registration</h3>

The <a href="#dfn-interaction-manager"
class="internalDFN">Interaction Manager</a> is actually used as
support to the <a href="#dfn-modality-component"
class="internalDFN">Modality Component's'</a> registration by the
use of Context requests. We propose to extend the <a
href="#dfn-interaction-manager" class="internalDFN">Interaction
Manager</a> to registration and discovery to avoid the complexity
of an approach that will add a new Component.<br />
<br />
 Figure 3 shows a possible example of registration in which a <a
href="#dfn-modality-component" class="internalDFN">Modality
Component</a> uses a StatusRequest/StatusResponse pair to
register its description on a known port. This is a case of fixed
discovery in which a <a href="#dfn-modality-component"
class="internalDFN">Modality Component</a> announces its presence
to the <a href="#dfn-interaction-manager"
class="internalDFN">Interaction Manager</a> and then, the <a
href="#dfn-interaction-manager" class="internalDFN">Interaction
Manager</a> insert this information in some registry according to
the implemented data Model.<br />
<br />
<a href="images/MMRegistering.png">
<img class="mmImage" src="images/MMRegistering.png" alt="Modality Components using a StatusRequest/StatusResponse pair to register its description" /></a><br />
<p class="caption">Figure 3: Modality Components using a StatusRequest/StatusResponse pair to register its description</p>
<br />
 Soft-state and hard-state registering depends on the <a
href="#dfn-modality-component" class="internalDFN">Modality
Component</a> lifetime information. In soft-state Advertisement a
registration renewal is needed. This mechanism of renewal <em
class="MMINote" title="should">should</em> be implemented with
attributes proposed in the MMI Architecture like the
RequestAutomaticUpdate or the ExtensionNotification. On the other
hand, explicit de-registration <em class="MMINote"
title="should">should</em> be implemented by the use of the Status
Event.<br />
<br />
 As a consequence of the structure of the MMI Architecture that
follows the 'Russian Doll' model, the distribution of Data
Components in nested <a href="#dfn-modality-component"
class="internalDFN">Modality Components</a> facilitates the
implementation of a multi-node Registry, which is a mechanism also
available in <a href="http://uddi.org/pubs/uddi_v3.htm">UDDI</a>,
<a href="http://river.apache.org/about.html">Jini</a> and <a
href="http://www.ietf.org/rfc/rfc2608.txt">SLP</a>. In this way the
balance of the registry load can be resolved using the nested <a
href="#dfn-data-component" class="internalDFN">Data Component</a>
structure. It will also depend on the implementation.

<h3 id="query"><span class="secno">4.5</span> Querying</h3>

In the MMI Architecture the query lifecycle <em class="MMINote"
title="must">must</em> be handled with the Interaction Life-cycle
Events Protocol. The monitoring of the state of a <a
href="#dfn-modality-component" class="internalDFN">Modality
Component</a> is a shared responsibility between the <a
href="#dfn-modality-component" class="internalDFN">Modality
Component</a> and the <a href="#dfn-interaction-manager"
class="internalDFN">Interaction Manager</a>. These components <em
class="MMINote" title="should">should</em> use StatusRequest/StatusResponse or
ExtensionNotifications to query updates, as showed in Figure 4.<br />
<br />
 The expressiveness of the discovery query and the format of the
query result can be defined by the Interaction Life-cycle Events
since the routing model depends on the implementation and is out of
the scope of this document.<br />
<br />
<a href="images/Query2.png">
<img class="mmImage" src="images/Query2.png" alt="Modality Components and Interaction Manager using StatusRequest/StatusResponse of ExtensionNotification events to query updates" /></a><br />
<p class="caption">Figure 4: 
Modality Components and Interaction Manager using StatusRequest/StatusResponse of ExtensionNotification events to query updates</p>
<br />
 The correctness of the result of the query can be ensured by a
pattern matching mechanism during the filtering and selection of <a
href="#dfn-modality-component" class="internalDFN">Modality
Components</a> based, in the case of a centralized registry
implementation, on the information stored as Descriptions of the <a
href="#dfn-modality-component" class="internalDFN">Modality
Component's</a> in the <a href="#dfn-data-component"
class="internalDFN">Data Component</a> Registry.<br />
<br />
 In the case of a distributed implementation in federated groups
(e.g. by modality type, capability, scope, zones, DNS subgroups or
intent categories), the correctness of the result of the query is
limited to the administrative boundary defined by the networking
underlying mechanism (e.g. <a
href="http://www.upnp.org/specs/arch/UPnP-arch-DeviceArchitecture-v1.0-20081015.pdf">
UPnP</a> or <a href="http://www.ietf.org/rfc/rfc2608.txt">SLP</a> )
which is also out of the scope of this document.

<h3 id="open-issues"><span class="secno">4.6</span> Open Issues</h3>

<p>During this work, the MMI Discovery and Registration Subgroup
did not have time to explore topics like Fault tolerance in <a
href="#dfn-modality-component" class="internalDFN">Modality
Component</a> nodes or in <a href="#dfn-modality-component"
class="internalDFN">Modality Component's'</a> communication during
discovery, register or state updates. Consistency maintenance is a
subject of extreme interest and the MMI Discovery and Registration
Subgroup would suggest the MMI working group to further investigate
this topic from the point of view of the MMI Architecture,
eventually with the use of specified attributes like the
RequestAutomaticUpdate or the Extension Notification and the use of
<a href="#dfn-modality-component" class="internalDFN">Modality
Component</a> States.</p>

<h2 id="related-works"><span class="secno">5.</span> Related Work</h2>

<h3 id="web-and-tv"><span class="secno">5.1</span> Web and TV Interest Group</h3>

<p>The Web and TV Interest Group's work covers
audio-visual content, e.g., broadcasting programs and Web pages,
and related services delivered by satellite and terrestrial
broadcasting, or via cable services, as well as delivery through
IP. This group is currently working on services discovery for
home-networking scenarios from the perspective of content
providing.</p>

<h3 id="Web-Intents"><span class="secno">5.2</span> Web Intents Task Force</h3>

<p>The Web Intents Task Force works on a joint deliverable of the
WebApps and Device APIs WGs that aims to produce a way for web
applications to register themselves as handlers for services, and
for other web applications to interact with such services (which
may have been registered through Intents or in other
implementation-specific manners) through simple requests brokered
by the user agent (a system commonly known as Intents, or
Activities). This Task Force is currently working on registering
for a limited type of modalities and from a unimodal perspective
oriented on process announcement and description.</p>

<h3 id="Protocols-and-Formats"><span class="secno">5.3</span> Protocols and Formats Working Group</h3>

<p>This working group covers the domain of web accessibility. Its
objective is to explore how to make web content usable by persons
with disabilities. The Accessible Rich Internet Applications
Candidate Recommendation is primarily focused on developers of Web
browsers, assistive technologies, and other user agents; developers
of Web technologies (technical specifications); and developers of
accessibility evaluation tools. WAI-ARIA provides a framework for
adding attributes to identify features for user interaction, how
they relate to each other, and their current state. WAI-ARIA
describes new navigation techniques to mark regions and common Web
structures as menus, primary content, secondary content, banner
information, and other types of Web structures. This work is mostly
oriented to web content, web UI components and web events
annotation.</p>

<h2 id="references"><span class="secno">A.</span> References</h2>

<h3 id="key-references"><span class="secno">A.1</span> Key References</h3>

<p></p>

<dl>
<dt id="bib-ECMA-262">[ECMA-262]</dt>

<dd>ECMA International. <a
href="http://www.ecma-international.org/publications/standards/Ecma-262.htm">
<cite>ECMAScript Language Specification, Third Edition.</cite></a>
December 1999. URL: <a
href="http://www.ecma-international.org/publications/standards/Ecma-262.htm">
http://www.ecma-international.org/publications/standards/Ecma-262.htm</a></dd>

<dt id="bib-EMMA">[EMMA]</dt>

<dd>Michael Johnston. <a
href="http://www.w3.org/TR/2009/REC-emma-20090210/"><cite>EMMA:
Extensible MultiModal Annotation markup language.</cite></a> 10
February 2009. W3C Recommendation. URL: <a
href="http://www.w3.org/TR/2009/REC-emma-20090210/">http://www.w3.org/TR/2009/REC-emma-20090210/</a></dd>

<dt id="bib-MMI-ARCH">[MMI-ARCH]</dt>

<dd>Jim Barnett. <a
href="http://www.w3.org/TR/2012/CR-mmi-arch-20120112/"><cite>Multimodal
Architecture and Interfaces.</cite></a> 12 January 2012. W3C
Candidate Recommendation. URL: <a
href="http://www.w3.org/TR/2012/CR-mmi-arch-20120112/">http://www.w3.org/TR/2012/CR-mmi-arch-20120112/</a></dd>

<dt id="bib-SLP">[SLP]</dt>

<dd>E. Guttman et al. <a
href="http://www.ietf.org/rfc/rfc2608.txt"><cite>RFC 2608: Service
Location Protocol.</cite></a> Version 2,1999. URL: <a
href="http://www.ietf.org/rfc/rfc2608.txt">http://www.ietf.org/rfc/rfc2608.txt</a></dd>

<dt id="bib-WSDL">[WSDL]</dt>

<dd>Roberto Chinnici,Jean-Jacques Moreau, Arthur Ryman, Sanjiva
Weerawarana. <a href="http://www.w3.org/TR/wsdl20/"><cite>A Web
Services Description Language</cite></a> WSDL, v.2.0, 26 June 2007.
URL: <a
href="http://www.w3.org/TR/wsdl20/">http://www.w3.org/TR/wsdl20/</a></dd>

<dt id="bib-XML">[XML]</dt>

<dd>Tim Bray, Jean Paoli, C.M. Sperberg-McQueen, Eve Maler, John
Cowan, François Yergeau. <a
href="http://www.w3.org/TR/xml11/"><cite>XML</cite></a> Extensible
Markup Language, XML 1.1, 4 February 2004. URL: <a
href="http://www.w3.org/TR/xml11/">http://www.w3.org/TR/xml11/</a></dd>

<dd><br />
<br />
 <br />
<br />
</dd>
</dl>

<h3 id="other-references"><span class="secno">A.2</span> Other References</h3>

<dl class="bibliography">
<dt id="bib-A-INTENT">[A-INTENT]</dt>

<dd>Google. <a
href="http://developer.android.com/reference/android/content/Intent.html">
<cite>Android Intent Class Documentation</cite></a> Available at
URL: <a
href="http://developer.android.com/reference/android/content/Intent.html">
http://developer.android.com/reference/android/content/Intent.html</a></dd>

<dt id="bib-ARIA">[ARIA]</dt>

<dd>James Craig et al. <a
href="http://developer.android.com/reference/android/content/Intent.html">
<cite>Accessible Rich Internet Applications</cite></a> WAI-ARIA
version 1.0. W3C Working Draft, 16 September 2010. Available at
URL: <a
href="http://www.w3.org/TR/wai-aria/">http://www.w3.org/TR/wai-aria/</a></dd>

<dt id="bib-ASN">[ASN.1]</dt>

<dd>John Larmouth, Douglas Steedman, James E. White. <a
href="http://www.itu.int/ITU-T/asn1/introduction/index.htm"><cite>ASN.1</cite></a>
International Telecommunication Union. ISO/IEC 8824-1 &gt; 8824-4.
Available at URL: <a
href="http://www.itu.int/ITU-T/asn1/introduction/index.htm">http://www.itu.int/ITU-T/asn1/introduction/index.htm</a></dd>

<dt id="bib-ECHONET">[ECHONET]</dt>

<dd>Echonet Consortium. <a
href="http://www.echonet.gr.jp/english/spec/pdf/spec_v1e_appendix.pdf">
<cite>Detailed stipulation for Echonet Device Objects</cite></a>
Available at URL: <a
href="http://www.echonet.gr.jp/english/spec/pdf/spec_v1e_appendix.pdf">
http://www.echonet.gr.jp/english/spec/pdf/spec_v1e_appendix.pdf</a></dd>

<dt id="bib-EMOTION-USE">[EMOTION-USE]</dt>

<dd>Marc Schröder, Enrico Zovato, Hannes Pirker,
Christian Peter, Felix Burkhardt. <a
href="http://www.w3.org/2005/Incubator/emotion/XGR-emotion/#AppendixUseCases">
<cite>Emotion Incubator Group Use Cases</cite></a> Available at
URL: <a
href="http://www.w3.org/2005/Incubator/emotion/XGR-emotion/#AppendixUseCases">
http://www.w3.org/2005/Incubator/emotion/XGR-emotion/#AppendixUseCases</a></dd>

<dt id="bib-IANA">[IANA]</dt>

<dd>IANA.<a href="http://www.iana.org/domains"><cite>IANA Domain
Name Service</cite></a> ICCAN - Internet Assigned Numbers Authority
(IANA). Available at URL: <a
href="http://www.iana.org/domains">http://www.iana.org/</a></dd>

<dt id="bib-INS">[INS]</dt>

<dd>William Adjie-Winoto, Elliot Schwartz, Hari Balakrishnan,
Jeremy Lilley. <a
href="http://nms.csail.mit.edu/projects/ins/"><cite>INS:
Intentional Naming System</cite></a> Available at URL: <a
href="http://nms.csail.mit.edu/projects/ins/">http://nms.csail.mit.edu/projects/ins/</a></dd>

<dt id="bib-JINI">[JINI]</dt>

<dd>Sun Microsystems <a
href="http://river.apache.org/about.html"><cite>JINI /
RIVER</cite></a> Apache River (formerly JINI). Available at URL: <a
href="http://river.apache.org/about.html">http://river.apache.org/about.html</a></dd>

<dt id="bib-INS-TWINE">[INS/TWINE]</dt>

<dd>Magdalena Balazinska, Hari Balakrishnan, David Karger <a
href="http://nms.csail.mit.edu/projects/twine/"><cite>INS /
TWINE</cite></a> Apache River (formerly JINI). Available at URL: <a
href="http://nms.csail.mit.edu/projects/twine/">http://nms.csail.mit.edu/projects/twine/</a></dd>

<dt id="bib-JXTA">[JXTA]</dt>

<dd>Sun Microsystems <a
href="http://jxta.kenai.com/Specifications/JXTAProtocols2_0.pdf"><cite>
Juxtapose JXTA Protocols Specification</cite></a> v2.0 October 16,
2007. v2.0 . Available at URL: <a
href="http://jxta.kenai.com/Specifications/JXTAProtocols2_0.pdf">http://jxta.kenai.com/Specifications/JXTAProtocols2_0.pdf</a></dd>

<dt id="bib-METEOR-S">[METEOR-S]</dt>

<dd>Kunal Verma, Karthik Gomadam, Amit P. Sheth, John A. Miller,
Zixin Wu. <a
href="http://lsdis.cs.uga.edu/projects/meteor-s/"><cite>METEOR-S:
Semantic Web Services and Processes</cite></a> Technical Report,
06/24/2005. Available at URL: <a
href="http://lsdis.cs.uga.edu/projects/meteor-s/">http://lsdis.cs.uga.edu/projects/meteor-s/</a></dd>

<dt id="bib-OGSA">[OGSA]</dt>

<dd>I. Foster, Argonne et al. <a
href="http://www.ogf.org/documents/GFD.80.pdf"><cite>OGSA</cite></a>
The Open Grid Services Architecture, 24 July 2006 Version 1.5.
Available at URL: <a
href="http://www.ogf.org/documents/GFD.80.pdf">http://www.ogf.org/documents/GFD.80.pdf</a></dd>

<dt id="bib-RES-DIS">[RES-DIS]</dt>

<dd>Reaz Ahmed et al. <a
href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5473882&amp;isnumber=5764312">
<cite>Resource and Service Discovery in Large-Scale Multi-Domain
Networks.</cite></a>in Ieee Communications Surveys &amp; Tutorials.
4Th Quarter 2007, Vol 9. Available at URL: <a
href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5473882&amp;isnumber=5764312">
http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=5473882&amp;isnumber=5764312</a></dd>

<dt id="bib-UDDI">[UDDI]</dt>

<dd>Luc Clement, Andrew Hately, Claus von Riegen, Tony Rogers. <a
href="http://uddi.org/pubs/uddi_v3.htm"><cite>UDDI</cite></a> Spec
Technical Committee Draft, Version 3.0.2. Dated 2004/10/19.
Available at URL: <a
href="http://uddi.org/pubs/uddi_v3.htm">http://uddi.org/pubs/uddi_v3.htm</a></dd>

<dt id="bib-UPNP-DEVICE">[UPNP-DEVICE]</dt>

<dd>UPnP Forum. <a
href="http://www.upnp.org/specs/arch/UPnP-arch-DeviceArchitecture-v1.0-20081015.pdf">
<cite>UPnP Device Architecture 1.0</cite></a> Version 1.0, 15
October 2008. PDF document. URL: <a
href="http://www.upnp.org/specs/arch/UPnP-arch-DeviceArchitecture-v1.0-20081015.pdf">
http://www.upnp.org/specs/arch/UPnP-arch-DeviceArchitecture-v1.0-20081015.pdf</a></dd>

<dt id="bib-UPNP-CONTENT">[UPNP-CONTENT]</dt>

<dd>UPnP Forum. <a
href="http://www.upnp.org/specs/av/UPnP-av-ContentDirectory-v4-Service-20101231.pdf">
<cite>ContentDirectory:4 Service</cite></a> Standardized DCP.
Version 1.0, 31 December 2010. PDF document.URL: <a
href="http://www.upnp.org/specs/av/UPnP-av-ContentDirectory-v4-Service-20101231.pdf">
http://www.upnp.org/specs/av/UPnP-av-ContentDirectory-v4-Service-20101231.pdf</a></dd>

<dt id="bib-WEB-INTENTS">[WEB-INTENTS]</dt>

<dd>Paul Kinlan. <a href="http://webintents.org/"><cite>Web
Intents.</cite></a> Available at URL: <a
href="http://webintents.org/">http://webintents.org/</a></dd>
</dl>
</body>
</html>

